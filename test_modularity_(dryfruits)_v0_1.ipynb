{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPWI61t/bJGuByMkWWyuEkE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IamRam3/dry-fruit-detection-segmentation/blob/main/test_modularity_(dryfruits)_v0_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from PIL import Image\n",
        "from pycocotools.coco import COCO\n",
        "import torch.utils.data\n",
        "import torchvision\n",
        "from torchvision.transforms import ToTensor\n",
        "from pycocotools.cocoeval import COCOeval\n",
        "import json\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor"
      ],
      "metadata": {
        "id": "WBDxZggPTPBE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "iVngo_ToTBci",
        "outputId": "26096f6b-caab-4ef3-e5a7-268dee6cfdf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'dry-fruit-detection-segmentation'...\n",
            "remote: Enumerating objects: 345, done.\u001b[K\n",
            "remote: Counting objects: 100% (345/345), done.\u001b[K\n",
            "remote: Compressing objects: 100% (320/320), done.\u001b[K\n",
            "remote: Total 345 (delta 51), reused 306 (delta 23), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (345/345), 24.37 MiB | 16.28 MiB/s, done.\n",
            "Resolving deltas: 100% (51/51), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/IamRam3/dry-fruit-detection-segmentation.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv dry-fruit-detection-segmentation dry_fruit_detection_segmentation"
      ],
      "metadata": {
        "id": "XxbNgGRtUUou"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf dry_fruit_detection_segmentation/"
      ],
      "metadata": {
        "id": "LMiZy9n0T8Bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dry_fruit_detection_segmentation.src.data_setup import CocoDataset, dataset_dir, CustomDataLoader\n",
        "from dry_fruit_detection_segmentation.utils import get_transform, convert_to_coco_format, get_detection_model, train, create_video_from_images"
      ],
      "metadata": {
        "id": "To-3MYjlTRJ_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "metadata": {
        "id": "R21ExtAETTat"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=4"
      ],
      "metadata": {
        "id": "yUD3XBfaTX6r"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rm -rf /content/DryFruits-classification.v1i.coco"
      ],
      "metadata": {
        "id": "cSSwJXeZDANF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/dry_fruit_detection_segmentation/datasets/labeled_dataset2/DryFruits-classification.v1i.coco.zip -d /content/DryFruits-classification.v1i.coco"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BVrUzgrIUPa_",
        "outputId": "8b1b7d4c-12b1-4370-ddf2-460dc41bddc7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/dry_fruit_detection_segmentation/datasets/labeled_dataset2/DryFruits-classification.v1i.coco.zip\n",
            "  inflating: /content/DryFruits-classification.v1i.coco/README.dataset.txt  \n",
            "  inflating: /content/DryFruits-classification.v1i.coco/README.roboflow.txt  \n",
            "   creating: /content/DryFruits-classification.v1i.coco/test/\n",
            " extracting: /content/DryFruits-classification.v1i.coco/test/360_F_1248363446_QWsdjuZlE2uK4sg1gCZSMogHM5d5SDqv_webp.rf.98746b3d6b7cd7d53599adf17435b3ff.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/test/ALMOND_REGULAR_ALMOND_REGULAR_753_jpg.rf.0fc0280f63ea517a12ddacfa2926d7c2.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/test/ALMOND_SANORA_ALMOND_SANORA_292_jpg.rf.ff6e25a988daba132ee36167d5d68c71.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/test/ALMOND_SANORA_ALMOND_SANORA_462_jpg.rf.26ce49555ae7916de41b848804580315.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/test/CASHEW_JUMBO_CASHEW_JUMBO_797_jpg.rf.2a382bd15579fa6f60f1caf5722564ce.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/test/CASHEW_REGULAR_CASHEW_REGULAR_947_jpg.rf.cdf6537a2440e0fa90a7d37292d0939c.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/test/RAISIN_BLACK_RAISIN_BLACK_857_jpg.rf.63fc2410f24e457ebc474a80cd814f96.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/test/RAISIN_GRADE1_RAISIN_GRADE1_293_jpg.rf.b0cdf0dd594d495c4ef809af7e557ad5.jpg  \n",
            "  inflating: /content/DryFruits-classification.v1i.coco/test/_annotations.coco.json  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/test/ripe-red-grape-one-berry-260nw-503311102_webp.rf.bf33be1071cd8c675f3e018e54eb591d.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/test/single-red-grape_webp.rf.9a4bb8331fc425ed99dceb4772b0bbe8.jpg  \n",
            "   creating: /content/DryFruits-classification.v1i.coco/train/\n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/360_F_1085743617_TZyeDIVCjcw4XbqBolKU0WC5ZqNpJ9Rc_webp.rf.ad3c75cc4f64dba03ce5a44afc58eb1d.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/360_F_1218179377_guXOLpOhmvKU3CIiq9HuduiE1PWsofRu_webp.rf.ba7f4f1a715388fd4016adf553ebd754.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/360_F_1230381194_JkZ4wWbmrdZ0gWxZJXFR6aHQ391xSS2m_webp.rf.fbb5696a3ead5cc8e9dbc43e85d81c84.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/360_F_1398457747_LeARvSkUcjYXu0jUuKbWv436VgQ8TPK8_webp.rf.dde327dd531ead532fe13278ec20e33e.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_180_jpg.rf.03d3e296bd5232416bf34b7013cd6a45.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_192_jpg.rf.10d0156c8a85c3cf9e96eb9f10fb46d5.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_234_jpg.rf.0f4b0ecaff24374c1fa9064fa7416b24.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_599_jpg.rf.3ffe5dcace97bee9710255c684820d33.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_778_jpg.rf.0e88a2c2ab42ad10e5b8142d4ef85bef.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_7_jpg.rf.1a25c06ef357d60556528edaf57b29ca.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_285_jpg.rf.af8bcbd952b0e90abeab468ccc52b9fc.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_333_jpg.rf.cab92353a39c5ac22c196fbe00528670.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_390_jpg.rf.17a6521484c26f6b714639afa804db4c.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_578_jpg.rf.f5491886bf6c47046cfaac2233619b94.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_806_jpg.rf.3ddf5b24ca65631dbf1fb528a6d7fa3d.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/ALMOND_SANORA_ALMOND_SANORA_113_jpg.rf.d6a438a98e252478f4a6d127fea04815.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/ALMOND_SANORA_ALMOND_SANORA_128_jpg.rf.7837550805cd36cc50a97e034f15bfb4.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/ALMOND_SANORA_ALMOND_SANORA_22_jpg.rf.1c4b595c20532ad64e7f9d2b42c0d554.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/ALMOND_SANORA_ALMOND_SANORA_429_jpg.rf.42925129521ba8e73dadbf6ae5d5d5b3.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/ALMOND_SANORA_ALMOND_SANORA_42_jpg.rf.da42bd6e053e8fa6e63ee817b8a5bf11.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/ALMOND_SANORA_ALMOND_SANORA_905_jpg.rf.3b342661884af165b9f4368a1134b76a.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_187_jpg.rf.6ec76d328626be65f168f974400855cf.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_310_jpg.rf.41c72ef6b41489f0235f633c0c2dea2a.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_466_jpg.rf.0a5db29da035f2dd385bb4d8f9bc7a1b.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_479_jpg.rf.3b4ab965a37071449accc981fbcabb71.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_510_jpg.rf.c7cdf34611908b393cb80096a21bac02.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_546_jpg.rf.8e2f1ed73e6699a93b9dc1f3c014dda7.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_904_jpg.rf.a52cbd596fedd34adbd2f588cb6943df.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_200_jpg.rf.d844c9816c92ab5e6843aca2501585f4.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_357_jpg.rf.64f07632084096bc679ba6e15fb9afbc.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_394_jpg.rf.e1153fcda05b39829bb0cef83e240948.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_605_jpg.rf.c9cf8a12516394212a3ba02582676b94.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_737_jpg.rf.506df3b13e957366012a578e5c518450.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_171_jpg.rf.bb3d5ea2103be958900291dc9dc12749.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_259_jpg.rf.188fd89d623ac51e4650a0943631a187.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_289_jpg.rf.f8e0aff0ecb55b8f5073f96ef634541d.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_46_jpg.rf.772ee010a86b7d9aa4f6ef866e4dc7af.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_471_jpg.rf.a2e82b4dbec37197e596216100cafc94.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_552_jpg.rf.7dbe7311bedf26de602f82fa84c13adf.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_724_jpg.rf.51b6fef316450c56d24b390c1ef2462d.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/RAISIN_BLACK_RAISIN_BLACK_128_jpg.rf.909415b8fb5239cf9483b04b86259cb2.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/RAISIN_BLACK_RAISIN_BLACK_246_jpg.rf.83dd41beee37366d397965cee1e66a47.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/RAISIN_BLACK_RAISIN_BLACK_261_jpg.rf.f3aafc0ca4ba6310ded6502add52bda3.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/RAISIN_BLACK_RAISIN_BLACK_568_jpg.rf.032026ff2cf1e62f9ceb1f58489aeb74.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/RAISIN_BLACK_RAISIN_BLACK_793_jpg.rf.cfa2aa9c42ba1e4d2c94d50c487e421a.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/RAISIN_BLACK_RAISIN_BLACK_812_jpg.rf.ce528a39158ee39b124a418061b45dac.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/RAISIN_BLACK_RAISIN_BLACK_846_jpg.rf.bbc3f59386229966dbfe3efae0771cec.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/RAISIN_GRADE1_RAISIN_GRADE1_421_jpg.rf.eceb171ac633fa24408b6f81f6e3548b.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/RAISIN_GRADE1_RAISIN_GRADE1_726_jpg.rf.2391502d34061edec9237317036f6fff.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/RAISIN_GRADE1_RAISIN_GRADE1_886_jpg.rf.448ff0415fd07b0633dee82ba180bbb7.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_164_jpg.rf.dc91173522eb71b6817eb0ffd079624f.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_186_jpg.rf.5a7e15e6736c3ef7dc2b4c316cdc49fb.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_244_jpg.rf.39516a97543c531f76d7801849cfc969.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_256_jpg.rf.e8372157c4308bdb4ebb854e55fdc5fe.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_25_jpg.rf.bf97aa63f586c884596d14bb4909d86a.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_73_jpg.rf.57d90b7ed424c2615a5f0e075ab26147.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_811_jpg.rf.458e8604b33d870b1b332fdfa1a739d0.jpg  \n",
            "  inflating: /content/DryFruits-classification.v1i.coco/train/_annotations.coco.json  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/a-single-grape-on-a-white-wall-photo_webp.rf.5bc3e07142344b723fe7b40ef42a7017.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/black-grapes-isolated-on-white-background-photo_webp.rf.6e60e2e69faf05f81c93c312b2a005c8.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/four-concord-grapes-isolated-on-white_webp.rf.cdd1929f980720a5f33b23d6eae67b99.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/front-view-of-fresh-red-grapes-with-half-in-stack-isolated-on-white-background-with-clipping-path-photo_webp.rf.054cbf39bc7f0f2fc68a8bc1030c432c.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/green-grape-isolated-on-white_webp.rf.1804b9397b59abb3afc8d229b13ab7a0.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/green-grapes-isolated-realistic-green-grapes-on-a-white-background-photo_webp.rf.7fc2c48b09cfec6cf500f852b63f48b1.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/high-angle-view-grapes-white-fabric_1048944-17885048_webp.rf.0a00e8bbf6c2e1bf895cbe1195ba6d9f.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/red-grape-macro_webp.rf.800c111974c3d596ff322b367a2738c4.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/red-grape-on-white-background-close-up-free-photo_webp.rf.99b7676c09ce5aca265059c2f3480c57.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/red-seedless-grape_webp.rf.57cbbc07053e648e4d998d3091a26be7.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/ripe-red-grape-isolated-on-white-with-clipping-path-full-depth-of-field_webp.rf.64715c931bd83b5d2293e638e3473b3d.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/two-purple-grapes-with-green-stems_webp.rf.b1c60c9506e3eba66ce44d512ee5cce2.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/train/white-grapes_webp.rf.ee5b765e9ff1dd914b914728de18201d.jpg  \n",
            "   creating: /content/DryFruits-classification.v1i.coco/valid/\n",
            " extracting: /content/DryFruits-classification.v1i.coco/valid/360_F_1349652285_d44dCkFXh7AyjP71uTiMOGeyFWOlkqoZ_webp.rf.ab308947de3088117f761502466062f4.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/valid/ALMOND_MAMRA_ALMOND_MAMRA_225_jpg.rf.e48aa286247248e1086a52025d7af434.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/valid/ALMOND_MAMRA_ALMOND_MAMRA_470_jpg.rf.dabab3f402c594aab32800d1fef78684.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/valid/ALMOND_MAMRA_ALMOND_MAMRA_740_jpg.rf.42ed96667421cb24a9901b86fae6dab1.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/valid/ALMOND_REGULAR_ALMOND_REGULAR_402_jpg.rf.7cded36aaa0f74e39d2faac4de8a69c9.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/valid/ALMOND_REGULAR_ALMOND_REGULAR_598_jpg.rf.b2443af47b43d93ab49f6fa95fef11fd.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/valid/CASHEW_JUMBO_CASHEW_JUMBO_471_jpg.rf.7b1d22aef79ef1234f7f517ddbe6d279.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/valid/CASHEW_REGULAR_CASHEW_REGULAR_863_jpg.rf.2dc64e4e7d0e2c9535febaf5a7e6e73b.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/valid/CASHEW_REGULAR_CASHEW_REGULAR_903_jpg.rf.b7534f65341bc3c8999563f8fca4b751.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/valid/CASHEW_SPECIAL_CASHEW_SPECIAL_593_jpg.rf.fb88edf787405425197eb7c08a06fc2a.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/valid/RAISIN_BLACK_RAISIN_BLACK_596_jpg.rf.f625d894ebc053c1dc279c8e4a53ee3e.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/valid/RAISIN_GRADE1_RAISIN_GRADE1_251_jpg.rf.fca1eca1d5fbe2fc36016bb1d539cedf.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/valid/RAISIN_GRADE1_RAISIN_GRADE1_258_jpg.rf.d9d3f928eaf2568418c735561ecb2185.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/valid/RAISIN_GRADE1_RAISIN_GRADE1_344_jpg.rf.e05fc46ba29b9e2150111b2966a67b39.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/valid/RAISIN_GRADE1_RAISIN_GRADE1_77_jpg.rf.f3b49d5f813cca4fdbf32df9bcc33cd7.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/valid/RAISIN_PREMIUM_RAISIN_PREMIUM_241_jpg.rf.eacca4a79b43eeba225f83eff1351ae5.jpg  \n",
            "  inflating: /content/DryFruits-classification.v1i.coco/valid/_annotations.coco.json  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/valid/one-purple-grape-isolated-on-a-black-background-showing-the-details-of-the-skin-and-texture-free-photo_webp.rf.cf5c1d0dbda4fa00592deac254d69a92.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/valid/picture-with-a-fresh-red-grape_webp.rf.44fc2aefaa9e66988edb048d4c1bcd37.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/valid/single-blue-grape-stem-isolated-260nw-152226398_webp.rf.20f68199bed28203d9ff3d1c7b1a27d7.jpg  \n",
            " extracting: /content/DryFruits-classification.v1i.coco/valid/wet-grape-on-white-background_webp.rf.0c02d22b00e6c474370d548947a4b88e.jpg  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/dry_fruit_detection_segmentation/datasets/labeled_dataset2/DryFruits-Detection.v2i.coco.zip -d /content/DryFruits-Detection.v2i.coco"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "D8GuqbjvVLMS",
        "outputId": "d3e1ad1d-2f02-4ded-cf37-ea0fdc81d714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/dry_fruit_detection_segmentation/datasets/labeled_dataset2/DryFruits-Detection.v2i.coco.zip\n",
            "  inflating: /content/DryFruits-Detection.v2i.coco/README.dataset.txt  \n",
            "  inflating: /content/DryFruits-Detection.v2i.coco/README.roboflow.txt  \n",
            "   creating: /content/DryFruits-Detection.v2i.coco/test/\n",
            " extracting: /content/DryFruits-Detection.v2i.coco/test/360_F_1248363446_QWsdjuZlE2uK4sg1gCZSMogHM5d5SDqv_webp.rf.98746b3d6b7cd7d53599adf17435b3ff.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/test/ALMOND_REGULAR_ALMOND_REGULAR_753_jpg.rf.0fc0280f63ea517a12ddacfa2926d7c2.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/test/ALMOND_SANORA_ALMOND_SANORA_292_jpg.rf.ff6e25a988daba132ee36167d5d68c71.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/test/ALMOND_SANORA_ALMOND_SANORA_462_jpg.rf.26ce49555ae7916de41b848804580315.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/test/CASHEW_JUMBO_CASHEW_JUMBO_797_jpg.rf.2a382bd15579fa6f60f1caf5722564ce.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/test/CASHEW_REGULAR_CASHEW_REGULAR_947_jpg.rf.cdf6537a2440e0fa90a7d37292d0939c.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/test/RAISIN_BLACK_RAISIN_BLACK_857_jpg.rf.63fc2410f24e457ebc474a80cd814f96.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/test/RAISIN_GRADE1_RAISIN_GRADE1_293_jpg.rf.b0cdf0dd594d495c4ef809af7e557ad5.jpg  \n",
            "  inflating: /content/DryFruits-Detection.v2i.coco/test/_annotations.coco.json  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/test/ripe-red-grape-one-berry-260nw-503311102_webp.rf.bf33be1071cd8c675f3e018e54eb591d.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/test/single-red-grape_webp.rf.9a4bb8331fc425ed99dceb4772b0bbe8.jpg  \n",
            "   creating: /content/DryFruits-Detection.v2i.coco/train/\n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/360_F_1085743617_TZyeDIVCjcw4XbqBolKU0WC5ZqNpJ9Rc_webp.rf.063d935e7c744250bb01e82b5688c1ec.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/360_F_1085743617_TZyeDIVCjcw4XbqBolKU0WC5ZqNpJ9Rc_webp.rf.229f3abab844e22aee7889b2a087ff24.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/360_F_1085743617_TZyeDIVCjcw4XbqBolKU0WC5ZqNpJ9Rc_webp.rf.ad3c75cc4f64dba03ce5a44afc58eb1d.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/360_F_1218179377_guXOLpOhmvKU3CIiq9HuduiE1PWsofRu_webp.rf.0b94e623c96bb768f089d2f3fc227bd1.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/360_F_1218179377_guXOLpOhmvKU3CIiq9HuduiE1PWsofRu_webp.rf.ba7f4f1a715388fd4016adf553ebd754.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/360_F_1218179377_guXOLpOhmvKU3CIiq9HuduiE1PWsofRu_webp.rf.d832e21c71e3094446a94ec9b53be400.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/360_F_1230381194_JkZ4wWbmrdZ0gWxZJXFR6aHQ391xSS2m_webp.rf.42fa704a3aadebc0cd129e0b059f3cf2.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/360_F_1230381194_JkZ4wWbmrdZ0gWxZJXFR6aHQ391xSS2m_webp.rf.c01148828afa7ab8689d39914a9988a9.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/360_F_1230381194_JkZ4wWbmrdZ0gWxZJXFR6aHQ391xSS2m_webp.rf.fbb5696a3ead5cc8e9dbc43e85d81c84.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/360_F_1398457747_LeARvSkUcjYXu0jUuKbWv436VgQ8TPK8_webp.rf.22b3af2defb9c864d6cab8405833f6d7.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/360_F_1398457747_LeARvSkUcjYXu0jUuKbWv436VgQ8TPK8_webp.rf.752e47f2c7e9664b49f37dcdd6ff9e31.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/360_F_1398457747_LeARvSkUcjYXu0jUuKbWv436VgQ8TPK8_webp.rf.dde327dd531ead532fe13278ec20e33e.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_180_jpg.rf.03d3e296bd5232416bf34b7013cd6a45.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_180_jpg.rf.0bb53760b60ddde48677eef42d22dd67.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_180_jpg.rf.e8b533aeefbd2ff4485d62ffb2554154.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_192_jpg.rf.10d0156c8a85c3cf9e96eb9f10fb46d5.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_192_jpg.rf.1bc6aa626c82380d9737f78ac25dea50.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_192_jpg.rf.44729723c050202f4a775101b1a16cf9.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_234_jpg.rf.0f4b0ecaff24374c1fa9064fa7416b24.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_234_jpg.rf.1a193a04f715eeb4b7d541e9840163f7.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_234_jpg.rf.910c9a9979b88b78cfa474715981e335.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_599_jpg.rf.2be47972d402ac88e801c5f1dd3e2b64.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_599_jpg.rf.3ffe5dcace97bee9710255c684820d33.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_599_jpg.rf.99a98d0aa325a9832b3c27dad1b23a22.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_778_jpg.rf.0e88a2c2ab42ad10e5b8142d4ef85bef.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_778_jpg.rf.af01a4aa43f5d4c11630b442aae40df0.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_778_jpg.rf.e5d7e274697b5ab4ee9ce24db0633ae9.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_7_jpg.rf.1a25c06ef357d60556528edaf57b29ca.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_7_jpg.rf.c017d0977cd1c9dc7aff61e9f8e0ea58.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_7_jpg.rf.c3e46035cbc026d46a8e05ca0db47246.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_285_jpg.rf.782d9b5486cd5ccb1fc2109c9a58d9e5.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_285_jpg.rf.af8bcbd952b0e90abeab468ccc52b9fc.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_285_jpg.rf.def880e44946d5b52c3b0c61d969a045.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_333_jpg.rf.2ca31f5bdc3155748adec6cef97ab5c6.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_333_jpg.rf.671812401334a5605a03dec8f7e0c486.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_333_jpg.rf.cab92353a39c5ac22c196fbe00528670.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_390_jpg.rf.17a6521484c26f6b714639afa804db4c.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_390_jpg.rf.3f9bf2540cd9d2c915a9c1d333131532.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_390_jpg.rf.9b0bd8f95f1f932f5b420fc55cd91633.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_578_jpg.rf.0aa83f40d3d163757e9a4dc5ae7db7e7.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_578_jpg.rf.1080be509c1858b892d9876bbe577497.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_578_jpg.rf.f5491886bf6c47046cfaac2233619b94.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_806_jpg.rf.0f7eb5713f8aef8e9a0388a6df03610a.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_806_jpg.rf.278c610b1189f9b7a7eff3ffcf585e1e.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_806_jpg.rf.3ddf5b24ca65631dbf1fb528a6d7fa3d.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_SANORA_ALMOND_SANORA_113_jpg.rf.0de5a238e0d4817d96e2c7e65ce837ea.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_SANORA_ALMOND_SANORA_113_jpg.rf.a57799b23ec58164d65f6d92d195b042.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_SANORA_ALMOND_SANORA_113_jpg.rf.d6a438a98e252478f4a6d127fea04815.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_SANORA_ALMOND_SANORA_128_jpg.rf.5858b3720ffacdfd844a72f35406b493.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_SANORA_ALMOND_SANORA_128_jpg.rf.5a3fd7fedda82f9bdeadb35002d271f7.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_SANORA_ALMOND_SANORA_128_jpg.rf.7837550805cd36cc50a97e034f15bfb4.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_SANORA_ALMOND_SANORA_22_jpg.rf.1c4b595c20532ad64e7f9d2b42c0d554.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_SANORA_ALMOND_SANORA_22_jpg.rf.31687c3eddf9eb4794d08c8f51a354f8.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_SANORA_ALMOND_SANORA_22_jpg.rf.6be639d2158fdffa4b059cd2c67aa72c.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_SANORA_ALMOND_SANORA_429_jpg.rf.42925129521ba8e73dadbf6ae5d5d5b3.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_SANORA_ALMOND_SANORA_429_jpg.rf.70f84fcb13ec43b381050fb101bedae0.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_SANORA_ALMOND_SANORA_429_jpg.rf.e76d899bb194cc0030b6d9872d8cde87.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_SANORA_ALMOND_SANORA_42_jpg.rf.021f5f0a209d53ab93a667f9ad1eb71b.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_SANORA_ALMOND_SANORA_42_jpg.rf.8190696ad4a0bb78d62bdb44731853d9.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_SANORA_ALMOND_SANORA_42_jpg.rf.da42bd6e053e8fa6e63ee817b8a5bf11.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_SANORA_ALMOND_SANORA_905_jpg.rf.3b342661884af165b9f4368a1134b76a.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ALMOND_SANORA_ALMOND_SANORA_905_jpg.rf.466cf10988331787efe0f90afe9d44a9.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_187_jpg.rf.6ec76d328626be65f168f974400855cf.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_187_jpg.rf.791f8523d3fe40cad5bc39d4830ce3b3.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_187_jpg.rf.fa347d67e7cd6954b4f6681006aa1e60.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_310_jpg.rf.193b222832aa57bc084d7158b780ef01.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_310_jpg.rf.41c72ef6b41489f0235f633c0c2dea2a.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_310_jpg.rf.66e0168973cd7307113cc74fca47a3cd.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_466_jpg.rf.0a5db29da035f2dd385bb4d8f9bc7a1b.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_466_jpg.rf.9d18839e675f953314b00765c06c2598.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_466_jpg.rf.af068ce91f98e1b15bb513b522d164d7.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_479_jpg.rf.3b4ab965a37071449accc981fbcabb71.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_479_jpg.rf.55c9be5d2d65d2eeef234a17812a7c12.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_479_jpg.rf.97bf89c003f28cc1b0bae85ca912e25d.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_510_jpg.rf.661e5465511a5cf1d2fdde4f7ac62430.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_510_jpg.rf.97239220ee51606333553f243c8a1c62.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_510_jpg.rf.c7cdf34611908b393cb80096a21bac02.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_546_jpg.rf.8e2f1ed73e6699a93b9dc1f3c014dda7.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_546_jpg.rf.db569a476cc182898546af37ac347cc5.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_546_jpg.rf.f5def41ea9dcb95256512c5155190c12.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_904_jpg.rf.1b3380b5db20fbd0ad2c25196046f1bd.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_904_jpg.rf.a52cbd596fedd34adbd2f588cb6943df.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_904_jpg.rf.d443c1f6d8a98dec2f5056de883eb2a9.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_200_jpg.rf.a8a8d3794550ae9b345617f8e41515f8.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_200_jpg.rf.c74940280e09c013cd9a214584976705.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_200_jpg.rf.d844c9816c92ab5e6843aca2501585f4.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_357_jpg.rf.64f07632084096bc679ba6e15fb9afbc.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_357_jpg.rf.7666629c4f5f06486d1f6605eb5e2eca.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_357_jpg.rf.c9a455a05b36e5a6a6cf23ddf2d003d3.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_394_jpg.rf.7c67a099ea24ed334c452b8d515d11b0.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_394_jpg.rf.c54412b873551902eb267e4a94bee5d8.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_394_jpg.rf.e1153fcda05b39829bb0cef83e240948.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_605_jpg.rf.542b2c5be665bf45480b810167324efc.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_605_jpg.rf.ab9f580a8f9851659b79553b2dc1085b.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_605_jpg.rf.c9cf8a12516394212a3ba02582676b94.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_737_jpg.rf.506df3b13e957366012a578e5c518450.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_737_jpg.rf.9bf7c065bca80ca8c416a6f7e762001a.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_737_jpg.rf.bf06668c24fdf5426fd57f388f33f70c.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_171_jpg.rf.3e6b1fdd2826ab721192f23284e840d8.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_171_jpg.rf.bb3d5ea2103be958900291dc9dc12749.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_171_jpg.rf.c9d9df5b382b4a13ac5a57a83e695756.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_259_jpg.rf.188fd89d623ac51e4650a0943631a187.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_259_jpg.rf.1c8b94574a0377c602c92820156ceec1.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_259_jpg.rf.fc6dd7e4c5695aeb244d839d283bd9ee.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_289_jpg.rf.d76a4b7b34623ceadc6b5f74d752de93.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_289_jpg.rf.f787a3d3dd903c11575a87611a35dc1f.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_289_jpg.rf.f8e0aff0ecb55b8f5073f96ef634541d.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_46_jpg.rf.0b67a7d2e8d3b25bc659d633610d6b9c.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_46_jpg.rf.52e32fada84c9ac7cd47839adb6f52f0.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_46_jpg.rf.772ee010a86b7d9aa4f6ef866e4dc7af.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_471_jpg.rf.a2e82b4dbec37197e596216100cafc94.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_471_jpg.rf.f03597e103ac68d28794de6a02772380.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_471_jpg.rf.f74bf5582457a2399ce0be2147577f72.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_552_jpg.rf.1d80dbdd7bbbb527d4b38219f615d347.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_552_jpg.rf.7dbe7311bedf26de602f82fa84c13adf.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_552_jpg.rf.e42df8bcbbb006c3ee3a01813d85675a.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_724_jpg.rf.4cd9b82ff66bf7631599fad0595d35ce.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_724_jpg.rf.51b6fef316450c56d24b390c1ef2462d.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_724_jpg.rf.cae032080d1b210b3acdef0b5780b1a4.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_128_jpg.rf.909415b8fb5239cf9483b04b86259cb2.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_128_jpg.rf.b2af3fb3f8baf8513f0e46169017317f.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_128_jpg.rf.d6df4950500f0429d10b3b47fc02511a.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_246_jpg.rf.21dc863e4f902c64d56d56223fe99e6e.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_246_jpg.rf.83dd41beee37366d397965cee1e66a47.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_246_jpg.rf.e582a067d33ba1a536c845f1df4e3c24.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_261_jpg.rf.92ed0ca35fbe325f6470d09f6469e015.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_261_jpg.rf.f3aafc0ca4ba6310ded6502add52bda3.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_261_jpg.rf.fb7a72bd9e86d4806c7acb26755a63c7.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_568_jpg.rf.032026ff2cf1e62f9ceb1f58489aeb74.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_568_jpg.rf.8dceadcc77958779d79fd733940ec7db.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_568_jpg.rf.f72b622bc1bf46d6870b8cc1bf4d5396.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_793_jpg.rf.8f3f21ff8ac1621692d3b4639af32e4f.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_793_jpg.rf.cfa2aa9c42ba1e4d2c94d50c487e421a.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_793_jpg.rf.f39f55150223daf932ba61a96cee9b8c.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_812_jpg.rf.4ab6fdfb3b2dd876c0750a6dddd9ec3a.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_812_jpg.rf.a61e2aa47f9c6d43b1ea8a6bc25108d1.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_812_jpg.rf.ce528a39158ee39b124a418061b45dac.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_846_jpg.rf.05e9ed2050325caf086d91f9b06da8fe.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_846_jpg.rf.4375283d638d9e245df87e077e79937e.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_846_jpg.rf.bbc3f59386229966dbfe3efae0771cec.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_GRADE1_RAISIN_GRADE1_421_jpg.rf.515da44f4db70ea26b303dfaea99ddb9.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_GRADE1_RAISIN_GRADE1_421_jpg.rf.7d8b51bec3ebab8f8550c129df303309.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_GRADE1_RAISIN_GRADE1_421_jpg.rf.eceb171ac633fa24408b6f81f6e3548b.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_GRADE1_RAISIN_GRADE1_726_jpg.rf.2391502d34061edec9237317036f6fff.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_GRADE1_RAISIN_GRADE1_726_jpg.rf.4b11937e77ae7beade406da8ad21ce90.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_GRADE1_RAISIN_GRADE1_726_jpg.rf.ef1e935ff3a67f4ddb18df14d4b2cd04.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_GRADE1_RAISIN_GRADE1_886_jpg.rf.448ff0415fd07b0633dee82ba180bbb7.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_GRADE1_RAISIN_GRADE1_886_jpg.rf.51749d1ea4f5dd440e8eed7b6b95b66f.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_GRADE1_RAISIN_GRADE1_886_jpg.rf.8c53fa6812da8b88e313ae73a474e4f2.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_164_jpg.rf.4d7ac14fea1ff61d2a6a9aee07f77226.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_164_jpg.rf.514703e08f2534abb0378af15d0e89d9.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_164_jpg.rf.dc91173522eb71b6817eb0ffd079624f.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_186_jpg.rf.5a7e15e6736c3ef7dc2b4c316cdc49fb.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_186_jpg.rf.971db0af66a18a003c17b7590f933b38.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_186_jpg.rf.f2fd48f03107691d7290c2cc58cc000b.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_244_jpg.rf.39516a97543c531f76d7801849cfc969.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_244_jpg.rf.c0acfc994ff24604fda46845d19e219f.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_244_jpg.rf.ccdccf7af2bcda8b995c3fa7b5fa13b6.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_256_jpg.rf.85fe52e17db4498f1334dbe19db56887.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_256_jpg.rf.e8372157c4308bdb4ebb854e55fdc5fe.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_256_jpg.rf.f5393f971140b438b2e949737c81a0bb.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_25_jpg.rf.29703122366f2e7f35adb3f4141fd014.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_25_jpg.rf.99dd16d6cfb3ad6760f07f6907b5b26e.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_25_jpg.rf.bf97aa63f586c884596d14bb4909d86a.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_73_jpg.rf.1f2688e60ae6b0a935d2a4d90329f8ed.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_73_jpg.rf.57d90b7ed424c2615a5f0e075ab26147.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_73_jpg.rf.c6d87b698b7a4b1072b0221efafe3571.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_811_jpg.rf.458e8604b33d870b1b332fdfa1a739d0.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_811_jpg.rf.90a57074b90ff93f9416816c9a8dac19.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_811_jpg.rf.9815e2c9806a704228f8d29075ecfea3.jpg  \n",
            "  inflating: /content/DryFruits-Detection.v2i.coco/train/_annotations.coco.json  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/a-single-grape-on-a-white-wall-photo_webp.rf.3469701314adadafe43cb530f79f6ae5.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/a-single-grape-on-a-white-wall-photo_webp.rf.5bc3e07142344b723fe7b40ef42a7017.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/a-single-grape-on-a-white-wall-photo_webp.rf.83778d967ecdd3626bdc9eaabaa5b32d.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/black-grapes-isolated-on-white-background-photo_webp.rf.0c032a3bf9975171029a507400bea5fd.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/black-grapes-isolated-on-white-background-photo_webp.rf.6e60e2e69faf05f81c93c312b2a005c8.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/black-grapes-isolated-on-white-background-photo_webp.rf.80b9aa27b21d13591a51b6990642b7a5.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/four-concord-grapes-isolated-on-white_webp.rf.3518f08c97dd8f51af5ef03970f24409.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/four-concord-grapes-isolated-on-white_webp.rf.cdd1929f980720a5f33b23d6eae67b99.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/four-concord-grapes-isolated-on-white_webp.rf.db1e01bebad91fce41088bb82e0d231e.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/front-view-of-fresh-red-grapes-with-half-in-stack-isolated-on-white-background-with-clipping-path-photo_webp.rf.054cbf39bc7f0f2fc68a8bc1030c432c.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/front-view-of-fresh-red-grapes-with-half-in-stack-isolated-on-white-background-with-clipping-path-photo_webp.rf.9e6ce6a9a64b8fa2277366b4e2d625c7.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/front-view-of-fresh-red-grapes-with-half-in-stack-isolated-on-white-background-with-clipping-path-photo_webp.rf.ad3fc4f27d0702ac76cb3bd26e8a4a9b.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/green-grape-isolated-on-white_webp.rf.0b7e1255b390a018643816f627780d57.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/green-grape-isolated-on-white_webp.rf.0ebdef073b55b56ca2c422a2474a5512.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/green-grape-isolated-on-white_webp.rf.1804b9397b59abb3afc8d229b13ab7a0.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/green-grapes-isolated-realistic-green-grapes-on-a-white-background-photo_webp.rf.0249e82b0c6dce3f6edd6351f67e9adf.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/green-grapes-isolated-realistic-green-grapes-on-a-white-background-photo_webp.rf.7fc2c48b09cfec6cf500f852b63f48b1.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/green-grapes-isolated-realistic-green-grapes-on-a-white-background-photo_webp.rf.b747507bc9f151a31408cd64d1563bf6.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/high-angle-view-grapes-white-fabric_1048944-17885048_webp.rf.0a00e8bbf6c2e1bf895cbe1195ba6d9f.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/high-angle-view-grapes-white-fabric_1048944-17885048_webp.rf.1693356ffdd20f75b364ef34abfd0507.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/high-angle-view-grapes-white-fabric_1048944-17885048_webp.rf.be90695f1db1d604ecafd4ba528feaa8.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/red-grape-macro_webp.rf.6381fc537707fb958f396778bcece0a6.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/red-grape-macro_webp.rf.800c111974c3d596ff322b367a2738c4.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/red-grape-macro_webp.rf.c2c4e41958b340a31f049533a7f635e2.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/red-grape-on-white-background-close-up-free-photo_webp.rf.415870295152d3392ef6cc4a8f3e8ccf.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/red-grape-on-white-background-close-up-free-photo_webp.rf.99b7676c09ce5aca265059c2f3480c57.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/red-grape-on-white-background-close-up-free-photo_webp.rf.bd086318369e80214344f31b78676212.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/red-seedless-grape_webp.rf.148d4a031115eef136825bad365e7824.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/red-seedless-grape_webp.rf.57cbbc07053e648e4d998d3091a26be7.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/red-seedless-grape_webp.rf.99e89c110e5a71d06bbeee476ddea31c.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ripe-red-grape-isolated-on-white-with-clipping-path-full-depth-of-field_webp.rf.4cade2d6d114029d72a8528431753bb9.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ripe-red-grape-isolated-on-white-with-clipping-path-full-depth-of-field_webp.rf.64715c931bd83b5d2293e638e3473b3d.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/ripe-red-grape-isolated-on-white-with-clipping-path-full-depth-of-field_webp.rf.ba4a66b50b2846dfa359a7c5a7678a6c.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/two-purple-grapes-with-green-stems_webp.rf.5df8aeb2f94bf24e12aaad23e215a2ed.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/two-purple-grapes-with-green-stems_webp.rf.6a0fa41d38ebd9f7cbef09620f763c2d.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/two-purple-grapes-with-green-stems_webp.rf.b1c60c9506e3eba66ce44d512ee5cce2.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/white-grapes_webp.rf.68e9d6cd182048869b29d6fb418e861d.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/white-grapes_webp.rf.c8fc4f0196a8e17fb37211dbe44e300f.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/train/white-grapes_webp.rf.ee5b765e9ff1dd914b914728de18201d.jpg  \n",
            "   creating: /content/DryFruits-Detection.v2i.coco/valid/\n",
            " extracting: /content/DryFruits-Detection.v2i.coco/valid/360_F_1349652285_d44dCkFXh7AyjP71uTiMOGeyFWOlkqoZ_webp.rf.ab308947de3088117f761502466062f4.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/valid/ALMOND_MAMRA_ALMOND_MAMRA_225_jpg.rf.e48aa286247248e1086a52025d7af434.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/valid/ALMOND_MAMRA_ALMOND_MAMRA_470_jpg.rf.dabab3f402c594aab32800d1fef78684.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/valid/ALMOND_MAMRA_ALMOND_MAMRA_740_jpg.rf.42ed96667421cb24a9901b86fae6dab1.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/valid/ALMOND_REGULAR_ALMOND_REGULAR_402_jpg.rf.7cded36aaa0f74e39d2faac4de8a69c9.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/valid/ALMOND_REGULAR_ALMOND_REGULAR_598_jpg.rf.b2443af47b43d93ab49f6fa95fef11fd.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/valid/CASHEW_JUMBO_CASHEW_JUMBO_471_jpg.rf.7b1d22aef79ef1234f7f517ddbe6d279.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/valid/CASHEW_REGULAR_CASHEW_REGULAR_863_jpg.rf.2dc64e4e7d0e2c9535febaf5a7e6e73b.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/valid/CASHEW_REGULAR_CASHEW_REGULAR_903_jpg.rf.b7534f65341bc3c8999563f8fca4b751.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/valid/CASHEW_SPECIAL_CASHEW_SPECIAL_593_jpg.rf.fb88edf787405425197eb7c08a06fc2a.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/valid/RAISIN_BLACK_RAISIN_BLACK_596_jpg.rf.f625d894ebc053c1dc279c8e4a53ee3e.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/valid/RAISIN_GRADE1_RAISIN_GRADE1_251_jpg.rf.fca1eca1d5fbe2fc36016bb1d539cedf.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/valid/RAISIN_GRADE1_RAISIN_GRADE1_258_jpg.rf.d9d3f928eaf2568418c735561ecb2185.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/valid/RAISIN_GRADE1_RAISIN_GRADE1_344_jpg.rf.e05fc46ba29b9e2150111b2966a67b39.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/valid/RAISIN_GRADE1_RAISIN_GRADE1_77_jpg.rf.f3b49d5f813cca4fdbf32df9bcc33cd7.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/valid/RAISIN_PREMIUM_RAISIN_PREMIUM_241_jpg.rf.eacca4a79b43eeba225f83eff1351ae5.jpg  \n",
            "  inflating: /content/DryFruits-Detection.v2i.coco/valid/_annotations.coco.json  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/valid/one-purple-grape-isolated-on-a-black-background-showing-the-details-of-the-skin-and-texture-free-photo_webp.rf.cf5c1d0dbda4fa00592deac254d69a92.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/valid/picture-with-a-fresh-red-grape_webp.rf.44fc2aefaa9e66988edb048d4c1bcd37.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/valid/single-blue-grape-stem-isolated-260nw-152226398_webp.rf.20f68199bed28203d9ff3d1c7b1a27d7.jpg  \n",
            " extracting: /content/DryFruits-Detection.v2i.coco/valid/wet-grape-on-white-background_webp.rf.0c02d22b00e6c474370d548947a4b88e.jpg  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/dry_fruit_detection_segmentation/datasets/labeled_dataset2/DryFruits-Segmentation.v1i.coco.zip -d /content/DryFruits-Segmentation.v1i.coco"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvp8icc1btqv",
        "outputId": "89add28c-417e-4a2f-ef3d-87de8cb1e832"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/dry_fruit_detection_segmentation/datasets/labeled_dataset2/DryFruits-Segmentation.v1i.coco.zip\n",
            "  inflating: /content/DryFruits-Segmentation.v1i.coco/README.dataset.txt  \n",
            "  inflating: /content/DryFruits-Segmentation.v1i.coco/README.roboflow.txt  \n",
            "   creating: /content/DryFruits-Segmentation.v1i.coco/test/\n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/test/360_F_1248363446_QWsdjuZlE2uK4sg1gCZSMogHM5d5SDqv_webp.rf.ee5a89bca40b5620557c06690a160e4c.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/test/ALMOND_REGULAR_ALMOND_REGULAR_806_jpg.rf.de00fdc33a36d4aed2d2b3354c47ed7c.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/test/ALMOND_SANORA_ALMOND_SANORA_292_jpg.rf.089d18d7179d9d70c86f32037cafe374.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/test/ALMOND_SANORA_ALMOND_SANORA_905_jpg.rf.822d8eb52e60f587dfb543e358580f32.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/test/CASHEW_SPECIAL_CASHEW_SPECIAL_552_jpg.rf.62b04ab628eded93e865b6e49ca4c433.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/test/RAISIN_BLACK_RAISIN_BLACK_846_jpg.rf.8f7ce9cf72ed3f369ffa4f91d661f747.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/test/RAISIN_GRADE1_RAISIN_GRADE1_344_jpg.rf.5a6b1d3212ae6069ff2be0b23de88057.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/test/RAISIN_PREMIUM_RAISIN_PREMIUM_241_jpg.rf.78508ce0eae2320bb4ca5e71233fdc6a.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/test/RAISIN_PREMIUM_RAISIN_PREMIUM_811_jpg.rf.ebbd579cc734150e51b64bb7d2e4c220.jpg  \n",
            "  inflating: /content/DryFruits-Segmentation.v1i.coco/test/_annotations.coco.json  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/test/green-grapes-isolated-realistic-green-grapes-on-a-white-background-photo_webp.rf.687a6a1ee3d99ba765da8607d2df8da4.jpg  \n",
            "   creating: /content/DryFruits-Segmentation.v1i.coco/train/\n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/360_F_1085743617_TZyeDIVCjcw4XbqBolKU0WC5ZqNpJ9Rc_webp.rf.ffd0767c5e1404d614477f1f2c411308.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/360_F_1230381194_JkZ4wWbmrdZ0gWxZJXFR6aHQ391xSS2m_webp.rf.1ac9575fec013cb7de087f6e4dc94331.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/360_F_1349652285_d44dCkFXh7AyjP71uTiMOGeyFWOlkqoZ_webp.rf.111c9b5d92c21fe59f425a1e9b50f09c.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/360_F_1398457747_LeARvSkUcjYXu0jUuKbWv436VgQ8TPK8_webp.rf.af207e1c181952a42fc222c54a76dfe4.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_180_jpg.rf.bb750825eccb079525d962449753ab74.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_192_jpg.rf.8487cdfaf946c7b4149afe5dfcb93112.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_234_jpg.rf.7c3efaf6e808d2be9c08d85b101b62cb.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_599_jpg.rf.640bc4ad5abecf8ef3e03a231a31f1ff.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_740_jpg.rf.5f49fcfdc1cf4dee1db211b9370db251.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_778_jpg.rf.916b885d31c708fc5224240c30979874.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_285_jpg.rf.4e36e5db426615f7c9c8e115b37bd6dc.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_333_jpg.rf.11b593f44f7d6eac87f099a78a73edc8.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_390_jpg.rf.4e3f066a9d456ab2fc869566f28a446b.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_402_jpg.rf.379e0865a48d9d4d26c60f756d4c7230.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_598_jpg.rf.64edc1df6093ada53c1101811daad038.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_753_jpg.rf.7448acb77e0aff93d49c76f027e08691.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/ALMOND_SANORA_ALMOND_SANORA_113_jpg.rf.2372b61bb858713c69f927f67d94adbf.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/ALMOND_SANORA_ALMOND_SANORA_128_jpg.rf.d1c20b0c8e572f2511778fab49bcbb55.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/ALMOND_SANORA_ALMOND_SANORA_22_jpg.rf.a3fa49c3d2787b61d178b6ce0b0900ba.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/ALMOND_SANORA_ALMOND_SANORA_462_jpg.rf.f7c0dd28239e4868404ddee624fc799c.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_187_jpg.rf.07eb7a8796f7c86b4d61242ca6d8c480.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_310_jpg.rf.4b7b6769e194443390d76d1aa9a186e5.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_466_jpg.rf.8f2567dec2cdd46d96061ae22c998628.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_471_jpg.rf.f8c3dd5676e062f75bee56b16c9fd51d.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_479_jpg.rf.4257f625052c92fc7bcc5b7d285353b1.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_510_jpg.rf.c3a25d6bf31e1c3ffae85a134c2d5e3c.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_797_jpg.rf.cd0d83209964720b8d070de66f9343b1.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_904_jpg.rf.bab7b9866281af2370c04bfc1d7ce408.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_200_jpg.rf.6a26f36bea2e342ed790057a2869fb02.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_394_jpg.rf.ba9d7c06828efbaf711c9fc185b3876a.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_605_jpg.rf.7c9b3498b0b653653de59a829c92c73d.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_737_jpg.rf.e8779f6bd471a533d902443c7d503d0e.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_863_jpg.rf.c8e63327715dfba9469b072fc29470b7.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_903_jpg.rf.f7c22211f667056c3b2b0fa925610c85.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_171_jpg.rf.02c2e24ca301d851798a27d294863cfd.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_259_jpg.rf.ca89a6ec39a5e83bbdb44c8daa8aa9d9.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_289_jpg.rf.74f318dba9fe37ce4d35eb710dded6ad.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_46_jpg.rf.d0fc4f4edcc5fa39299a1cfed9ad1d48.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_471_jpg.rf.c2228445712d8cecf7b5d86f7c5b3337.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_593_jpg.rf.a32012c0ddfabfaac5a65eeb9568abf1.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_724_jpg.rf.da554b48e273cde3f921ef23b55585ae.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/RAISIN_BLACK_RAISIN_BLACK_128_jpg.rf.56ac59dfd413b1f8a683ef37e46b66c0.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/RAISIN_BLACK_RAISIN_BLACK_261_jpg.rf.f9354b88d78e22aed8adc6ffaf167ea1.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/RAISIN_BLACK_RAISIN_BLACK_568_jpg.rf.c3f1cd06b120f25a99ee249d8cbe794f.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/RAISIN_BLACK_RAISIN_BLACK_596_jpg.rf.6a4dddc29890904a846bf0e653d1ff0b.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/RAISIN_BLACK_RAISIN_BLACK_793_jpg.rf.4ef1657e5e6f2d8deab1d804169348c1.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/RAISIN_BLACK_RAISIN_BLACK_812_jpg.rf.01027d62fb36d632149fb6cf320a2cc0.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/RAISIN_BLACK_RAISIN_BLACK_857_jpg.rf.ba7a9e973bbb8f39dea2e992e58d33c4.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/RAISIN_GRADE1_RAISIN_GRADE1_251_jpg.rf.e9ce5071a5695d2d7f7591d2042cc251.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/RAISIN_GRADE1_RAISIN_GRADE1_293_jpg.rf.ae6677ec561f44fd28de7f9631fc1d28.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/RAISIN_GRADE1_RAISIN_GRADE1_726_jpg.rf.17c1f4559229613b2e47e3de9583dcec.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/RAISIN_GRADE1_RAISIN_GRADE1_886_jpg.rf.b4eb62751e4b686d4e435be583e5e53f.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_186_jpg.rf.7ee140a9856360d442825fbac08b3c81.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_244_jpg.rf.c2e9ba10634ad14e4d1daffc6272e83a.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_256_jpg.rf.5b003b5a5381f9b31216ef2cda6de507.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_25_jpg.rf.d86474239d700460204d898a0dcd5fb1.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_73_jpg.rf.50e8b7bf0cfa13dc88f82f6f04c37830.jpg  \n",
            "  inflating: /content/DryFruits-Segmentation.v1i.coco/train/_annotations.coco.json  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/a-single-grape-on-a-white-wall-photo_webp.rf.fed4e6c6291c2d1e838afedfe9e74acd.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/four-concord-grapes-isolated-on-white_webp.rf.f21dccb94874eb1b0dca2d2639ae2112.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/front-view-of-fresh-red-grapes-with-half-in-stack-isolated-on-white-background-with-clipping-path-photo_webp.rf.3cbcc297588d495428430d3057276250.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/green-grape-isolated-on-white_webp.rf.e7943b4ca8133d12f2aac688f074297a.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/high-angle-view-grapes-white-fabric_1048944-17885048_webp.rf.7fefe4af0f990b6fddacca31e202a9e4.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/one-purple-grape-isolated-on-a-black-background-showing-the-details-of-the-skin-and-texture-free-photo_webp.rf.d49dbd01734b5c8662f254e29e23da49.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/red-grape-macro_webp.rf.a9849175e49eac8f958ae1d558710933.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/red-grape-on-white-background-close-up-free-photo_webp.rf.594859fd77207bc016e53bcf621d713e.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/red-seedless-grape_webp.rf.54e90328aba0d280260f204551990bd7.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/ripe-red-grape-one-berry-260nw-503311102_webp.rf.81a122409e6bcd2e0cd87c3b35f511f4.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/single-blue-grape-stem-isolated-260nw-152226398_webp.rf.905074fa2de24330f6bdbcb0376b95e3.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/single-red-grape_webp.rf.5565292c9dd192163de63d574e844592.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/train/white-grapes_webp.rf.cd9eeb110c95b184451fef7dc486da3c.jpg  \n",
            "   creating: /content/DryFruits-Segmentation.v1i.coco/valid/\n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/valid/360_F_1218179377_guXOLpOhmvKU3CIiq9HuduiE1PWsofRu_webp.rf.20afe6835a63eaaf3c909d837d26cac0.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/valid/ALMOND_MAMRA_ALMOND_MAMRA_225_jpg.rf.3dcaa22b921ce8a1544a3fd11240b53c.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/valid/ALMOND_MAMRA_ALMOND_MAMRA_470_jpg.rf.6e77c73a1e5fc99c395490e34cc990e6.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/valid/ALMOND_MAMRA_ALMOND_MAMRA_7_jpg.rf.1156fad4657f61ea5443097fbae10e85.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/valid/ALMOND_REGULAR_ALMOND_REGULAR_578_jpg.rf.42471a772eaca2d304a3dc3d5bdc9da2.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/valid/ALMOND_SANORA_ALMOND_SANORA_429_jpg.rf.c40be853c3e3f3817db0be7a2f8109f8.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/valid/ALMOND_SANORA_ALMOND_SANORA_42_jpg.rf.8938726fc836a3f4a62226fc3b478642.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/valid/CASHEW_JUMBO_CASHEW_JUMBO_546_jpg.rf.c9bded083b5400cc729f4a4488633fed.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/valid/CASHEW_REGULAR_CASHEW_REGULAR_357_jpg.rf.0d84526d7e8363bf57803bc3ea4ad29f.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/valid/CASHEW_REGULAR_CASHEW_REGULAR_947_jpg.rf.0b001b5c3c102ebe0fa647ef4c30d0f5.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/valid/RAISIN_BLACK_RAISIN_BLACK_246_jpg.rf.7e8e786f6ff7b85d0b3de664c5309aeb.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/valid/RAISIN_GRADE1_RAISIN_GRADE1_258_jpg.rf.438b1b1360a04ccc905f0c9c8fb33e13.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/valid/RAISIN_GRADE1_RAISIN_GRADE1_421_jpg.rf.9d527a8ef3910fed3b6292e65ac4c08a.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/valid/RAISIN_GRADE1_RAISIN_GRADE1_77_jpg.rf.24ff7564b65216128730e3d4abc2ac6d.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/valid/RAISIN_PREMIUM_RAISIN_PREMIUM_164_jpg.rf.319366a9b055aa34a25aec7b3cb545d2.jpg  \n",
            "  inflating: /content/DryFruits-Segmentation.v1i.coco/valid/_annotations.coco.json  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/valid/black-grapes-isolated-on-white-background-photo_webp.rf.73051d3c82071a4e0ac0a38555e4bb83.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/valid/picture-with-a-fresh-red-grape_webp.rf.80a439b7c124835ffa767ff2ad454059.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/valid/ripe-red-grape-isolated-on-white-with-clipping-path-full-depth-of-field_webp.rf.1dc6409b9f990327718501bbe6e2bd62.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/valid/two-purple-grapes-with-green-stems_webp.rf.dec748accae0914de4ab7c0cba1abe7d.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v1i.coco/valid/wet-grape-on-white-background_webp.rf.ae3299c74d1755af68f89158458320e2.jpg  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/dry_fruit_detection_segmentation/datasets/labeled_dataset2/DryFruits-Segmentation.v2i.coco.zip -d /content/DryFruits-Segmentation.v2i.coco"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ScsIUbxubmdB",
        "outputId": "5a255bd6-74a9-4596-cf02-d566ddfbcdea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/dry_fruit_detection_segmentation/datasets/labeled_dataset2/DryFruits-Segmentation.v2i.coco.zip\n",
            "  inflating: /content/DryFruits-Segmentation.v2i.coco/README.dataset.txt  \n",
            "  inflating: /content/DryFruits-Segmentation.v2i.coco/README.roboflow.txt  \n",
            "   creating: /content/DryFruits-Segmentation.v2i.coco/test/\n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/test/360_F_1248363446_QWsdjuZlE2uK4sg1gCZSMogHM5d5SDqv_webp.rf.ee5a89bca40b5620557c06690a160e4c.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/test/ALMOND_REGULAR_ALMOND_REGULAR_806_jpg.rf.de00fdc33a36d4aed2d2b3354c47ed7c.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/test/ALMOND_SANORA_ALMOND_SANORA_292_jpg.rf.089d18d7179d9d70c86f32037cafe374.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/test/ALMOND_SANORA_ALMOND_SANORA_905_jpg.rf.822d8eb52e60f587dfb543e358580f32.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/test/CASHEW_SPECIAL_CASHEW_SPECIAL_552_jpg.rf.62b04ab628eded93e865b6e49ca4c433.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/test/RAISIN_BLACK_RAISIN_BLACK_846_jpg.rf.8f7ce9cf72ed3f369ffa4f91d661f747.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/test/RAISIN_GRADE1_RAISIN_GRADE1_344_jpg.rf.5a6b1d3212ae6069ff2be0b23de88057.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/test/RAISIN_PREMIUM_RAISIN_PREMIUM_241_jpg.rf.78508ce0eae2320bb4ca5e71233fdc6a.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/test/RAISIN_PREMIUM_RAISIN_PREMIUM_811_jpg.rf.ebbd579cc734150e51b64bb7d2e4c220.jpg  \n",
            "  inflating: /content/DryFruits-Segmentation.v2i.coco/test/_annotations.coco.json  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/test/green-grapes-isolated-realistic-green-grapes-on-a-white-background-photo_webp.rf.687a6a1ee3d99ba765da8607d2df8da4.jpg  \n",
            "   creating: /content/DryFruits-Segmentation.v2i.coco/train/\n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/360_F_1085743617_TZyeDIVCjcw4XbqBolKU0WC5ZqNpJ9Rc_webp.rf.e1142f2a64bbea36505693474c21ab6a.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/360_F_1085743617_TZyeDIVCjcw4XbqBolKU0WC5ZqNpJ9Rc_webp.rf.fd289b4361e6674a4c5798e74e20ffd8.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/360_F_1085743617_TZyeDIVCjcw4XbqBolKU0WC5ZqNpJ9Rc_webp.rf.ffd0767c5e1404d614477f1f2c411308.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/360_F_1230381194_JkZ4wWbmrdZ0gWxZJXFR6aHQ391xSS2m_webp.rf.12ffe391cfd31e2fece1b1da8696131d.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/360_F_1230381194_JkZ4wWbmrdZ0gWxZJXFR6aHQ391xSS2m_webp.rf.1ac9575fec013cb7de087f6e4dc94331.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/360_F_1230381194_JkZ4wWbmrdZ0gWxZJXFR6aHQ391xSS2m_webp.rf.25254a4096a0334b9b552908f54704ed.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/360_F_1349652285_d44dCkFXh7AyjP71uTiMOGeyFWOlkqoZ_webp.rf.111c9b5d92c21fe59f425a1e9b50f09c.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/360_F_1349652285_d44dCkFXh7AyjP71uTiMOGeyFWOlkqoZ_webp.rf.a02d2e2a4a7290cf45a9fb86d0489119.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/360_F_1349652285_d44dCkFXh7AyjP71uTiMOGeyFWOlkqoZ_webp.rf.fad886b4f432f2da6e1373dc117e1e99.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/360_F_1398457747_LeARvSkUcjYXu0jUuKbWv436VgQ8TPK8_webp.rf.a67a479268eb0d8a8a91e8b091ffa4b3.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/360_F_1398457747_LeARvSkUcjYXu0jUuKbWv436VgQ8TPK8_webp.rf.af207e1c181952a42fc222c54a76dfe4.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/360_F_1398457747_LeARvSkUcjYXu0jUuKbWv436VgQ8TPK8_webp.rf.af27f0f1a5fba7753ba3c7e94a8cd86b.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_180_jpg.rf.37ee17e939f2b7fcd044663d619c8d87.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_180_jpg.rf.bb750825eccb079525d962449753ab74.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_180_jpg.rf.bb944c56d6f00bfd2034047e31645b57.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_192_jpg.rf.55fd5c86fbdf4e0be305920359529d6c.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_192_jpg.rf.8487cdfaf946c7b4149afe5dfcb93112.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_192_jpg.rf.abee63a84f4d23e30249d2c2966fe0a9.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_234_jpg.rf.46f823c8cf4db699821cf0294326eef2.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_234_jpg.rf.5baac51599565567f6fe1973c2b22baf.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_234_jpg.rf.7c3efaf6e808d2be9c08d85b101b62cb.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_599_jpg.rf.640bc4ad5abecf8ef3e03a231a31f1ff.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_599_jpg.rf.a96ec3754f74110a04926e0fb562b428.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_599_jpg.rf.c9d6d4afdd6f1d65047e20a2611deeae.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_740_jpg.rf.3d2c2e31cfdb828f8965df3aa1201a71.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_740_jpg.rf.5f49fcfdc1cf4dee1db211b9370db251.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_740_jpg.rf.822fb8c77dcf5504aff40c1af60691d8.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_778_jpg.rf.916b885d31c708fc5224240c30979874.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_778_jpg.rf.b9698b40a69bbb16f55fbf4dae738c72.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_778_jpg.rf.f6b7625cca6a66e4761fccd05f3f5628.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_285_jpg.rf.4e36e5db426615f7c9c8e115b37bd6dc.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_285_jpg.rf.5d8b962f4ff07b97ed160a769aaf09cd.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_285_jpg.rf.7079dd757319a1c29c21be84d32b679b.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_333_jpg.rf.11b593f44f7d6eac87f099a78a73edc8.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_333_jpg.rf.53bbb60e346647042e9f16b81252469c.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_333_jpg.rf.8ac7e0ed04d97e75005151ce1a797cbb.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_390_jpg.rf.4e3f066a9d456ab2fc869566f28a446b.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_390_jpg.rf.7152ed90dcc0d0d17b79de68ac43ddeb.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_390_jpg.rf.91781ce91ba1237454d18633d94f2f0b.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_402_jpg.rf.2246f08dca43bd06837a72e9a944389e.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_402_jpg.rf.379e0865a48d9d4d26c60f756d4c7230.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_402_jpg.rf.d14242aac4c48f29fc7a83a1a10f07c5.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_598_jpg.rf.64edc1df6093ada53c1101811daad038.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_598_jpg.rf.b3d0ec03b8665ced3a6460b52f96d011.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_598_jpg.rf.cac4bda21d8407f24e908f2db13bd39a.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_753_jpg.rf.7448acb77e0aff93d49c76f027e08691.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_753_jpg.rf.ba1109c7c35973cac89564831d9d5432.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_753_jpg.rf.eabb5711d782f916ab45c5c89a226d4c.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_SANORA_ALMOND_SANORA_113_jpg.rf.2372b61bb858713c69f927f67d94adbf.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_SANORA_ALMOND_SANORA_113_jpg.rf.3b4c7235cb0935a7484d6cbdbca252a4.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_SANORA_ALMOND_SANORA_113_jpg.rf.8f13603bad78977576cb70473ebc1d43.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_SANORA_ALMOND_SANORA_128_jpg.rf.58fd262db6e58b534f876591b54fd92d.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_SANORA_ALMOND_SANORA_128_jpg.rf.5ff789615f754679d6396ee1737e56e1.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_SANORA_ALMOND_SANORA_128_jpg.rf.d1c20b0c8e572f2511778fab49bcbb55.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_SANORA_ALMOND_SANORA_22_jpg.rf.2f105c1803611158e0c7b8736a0ae226.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_SANORA_ALMOND_SANORA_22_jpg.rf.a3fa49c3d2787b61d178b6ce0b0900ba.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_SANORA_ALMOND_SANORA_22_jpg.rf.a859e32db48c80c4b06d105c09ae1910.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_SANORA_ALMOND_SANORA_462_jpg.rf.2a48c67358c376fe2a6d71876042acd1.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_SANORA_ALMOND_SANORA_462_jpg.rf.e06e94453b8a3066e6bb63fcf6940723.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_SANORA_ALMOND_SANORA_462_jpg.rf.f7c0dd28239e4868404ddee624fc799c.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_187_jpg.rf.07eb7a8796f7c86b4d61242ca6d8c480.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_187_jpg.rf.9c01ed0c3efcb2568bca788fad085bc1.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_187_jpg.rf.afb85fd6e5aab9b2985e317f29acd95e.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_310_jpg.rf.4b7b6769e194443390d76d1aa9a186e5.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_310_jpg.rf.abd0676232d9fa8372666674d6c9fa98.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_310_jpg.rf.e3b2ee00ae5163bf3ecc36d8b3719027.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_466_jpg.rf.13d11824af911c664dd12e911d036e7c.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_466_jpg.rf.6f1529492c73a2216c38eb9d2e4fcec4.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_466_jpg.rf.8f2567dec2cdd46d96061ae22c998628.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_471_jpg.rf.72907f6844929a3e55d0093333bbb5f5.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_471_jpg.rf.f8c3dd5676e062f75bee56b16c9fd51d.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_471_jpg.rf.ff43263db2b128d022e01087cc140e6a.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_479_jpg.rf.4257f625052c92fc7bcc5b7d285353b1.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_479_jpg.rf.83fa9aa5d6fd188bc182d853f6b4fdae.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_479_jpg.rf.f12300d084cef4f8d341b4b1415da8ab.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_510_jpg.rf.0a03601699139915bd90dc4553b33b8d.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_510_jpg.rf.342135631862dc96e5dff83f11f59bd1.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_510_jpg.rf.c3a25d6bf31e1c3ffae85a134c2d5e3c.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_797_jpg.rf.5e0aba4434362e611a82636c2a195f93.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_797_jpg.rf.a982a4f63991662a461782bec50c8f5a.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_797_jpg.rf.cd0d83209964720b8d070de66f9343b1.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_904_jpg.rf.923f51e7c466ff6535c0d622f08fca7f.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_904_jpg.rf.b16cc97bffe4d9d4ec9e8ebd12cc9d76.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_904_jpg.rf.bab7b9866281af2370c04bfc1d7ce408.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_200_jpg.rf.41d92a83f2d7c8eca85c1429dc9241cf.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_200_jpg.rf.6a26f36bea2e342ed790057a2869fb02.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_200_jpg.rf.b45da421d2c1fb8e7181ffff7aa4f343.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_394_jpg.rf.0bff77d0a82db8cbc8b69af9ec099bbc.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_394_jpg.rf.3798ef43dcb0d40a439c9c195fd5b845.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_394_jpg.rf.ba9d7c06828efbaf711c9fc185b3876a.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_605_jpg.rf.1bf8130d64a37609b31ed4676ed28669.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_605_jpg.rf.72ca4c915eafefe568d1efdbe231f715.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_605_jpg.rf.7c9b3498b0b653653de59a829c92c73d.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_737_jpg.rf.b856041ffd804ffe644099dfd25aea17.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_737_jpg.rf.e8779f6bd471a533d902443c7d503d0e.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_737_jpg.rf.f27af366a116265bab6c3b47d0d5aaa6.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_863_jpg.rf.64e3be5226d7bacacc866fb9b875053d.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_863_jpg.rf.9a4dbd470681b28c98e12512f2472ba0.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_863_jpg.rf.c8e63327715dfba9469b072fc29470b7.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_903_jpg.rf.4fb488ba6345a9d394b73d79f497b47a.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_903_jpg.rf.9434ff7bbed2d91ea5da4458654f46a5.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_903_jpg.rf.f7c22211f667056c3b2b0fa925610c85.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_171_jpg.rf.02c2e24ca301d851798a27d294863cfd.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_171_jpg.rf.2f985247b1bcb98b1b976aa2b5de42de.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_171_jpg.rf.5423ac28e9ee7a2baea2ec661ba18761.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_259_jpg.rf.192353e42aa86e8fed963fa0e58e853d.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_259_jpg.rf.c4590d47978bb062193dd2bcda4a17b1.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_259_jpg.rf.ca89a6ec39a5e83bbdb44c8daa8aa9d9.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_289_jpg.rf.659cbe49d654b6c152a92dd784fd87b8.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_289_jpg.rf.74f318dba9fe37ce4d35eb710dded6ad.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_289_jpg.rf.c9028e5b920c7da8bedf94a28d7a755c.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_46_jpg.rf.21fcc08f5b03a9c9d09e5152bbcbd7be.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_46_jpg.rf.a251827c15f4f9ffadbb9224764f9f6b.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_46_jpg.rf.d0fc4f4edcc5fa39299a1cfed9ad1d48.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_471_jpg.rf.0566861cd55ae76a33093c8865ca768d.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_471_jpg.rf.9cdc06611f986bd8b97de8773dec1f31.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_471_jpg.rf.c2228445712d8cecf7b5d86f7c5b3337.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_593_jpg.rf.7caab91b6310c7de25359c81daa42980.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_593_jpg.rf.a32012c0ddfabfaac5a65eeb9568abf1.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_593_jpg.rf.ec9a54b9b99381d5ddb4f3ad1459a510.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_724_jpg.rf.b5456f13b1701677d8231bb9c736e41a.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_724_jpg.rf.d36bc1bf86931eafa387b199d321adea.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_724_jpg.rf.da554b48e273cde3f921ef23b55585ae.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_128_jpg.rf.56ac59dfd413b1f8a683ef37e46b66c0.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_128_jpg.rf.c88e684a8419bff15b4eb7160cd4338d.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_128_jpg.rf.c9ef60fe38c2dc883c3ebc47d67f88c8.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_261_jpg.rf.5853118adbc7115a41d3f53fd3d91a79.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_261_jpg.rf.754d245bdd463a1226bff301febb5cd9.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_261_jpg.rf.f9354b88d78e22aed8adc6ffaf167ea1.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_568_jpg.rf.0e8bb682e7f29d685d493eb273afda02.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_568_jpg.rf.71d14e3dca15c9a21c747dde769f7205.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_568_jpg.rf.c3f1cd06b120f25a99ee249d8cbe794f.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_596_jpg.rf.3bbbedf1fc2f881264a7ca78232b5c2b.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_596_jpg.rf.6a4dddc29890904a846bf0e653d1ff0b.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_596_jpg.rf.7a25d010d1566ede7104e9cb605591ce.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_793_jpg.rf.1d420c190364b9d155e80cccb4543500.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_793_jpg.rf.201c21b9a87115350bc78aca0fb1fa28.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_793_jpg.rf.4ef1657e5e6f2d8deab1d804169348c1.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_812_jpg.rf.01027d62fb36d632149fb6cf320a2cc0.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_812_jpg.rf.3fdf8009d3aa6ff4597c0a6af05358c1.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_812_jpg.rf.df0b8e1d48ab068aa63fb957f60037c6.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_857_jpg.rf.ba7a9e973bbb8f39dea2e992e58d33c4.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_857_jpg.rf.d1b7bb8ee1ca362c1dc286265b57703d.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_857_jpg.rf.e38f797f32ffe5a735c07827b34d6875.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_GRADE1_RAISIN_GRADE1_251_jpg.rf.8d097a81db95a28e884396f966edabae.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_GRADE1_RAISIN_GRADE1_251_jpg.rf.99a0c5eb10d4ed2a329240307f3bccb7.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_GRADE1_RAISIN_GRADE1_251_jpg.rf.e9ce5071a5695d2d7f7591d2042cc251.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_GRADE1_RAISIN_GRADE1_293_jpg.rf.6a25973423bc3265e0e8757163be858c.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_GRADE1_RAISIN_GRADE1_293_jpg.rf.722c3715ee8ac5dd3342ceee33e9518b.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_GRADE1_RAISIN_GRADE1_293_jpg.rf.ae6677ec561f44fd28de7f9631fc1d28.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_GRADE1_RAISIN_GRADE1_726_jpg.rf.088511df8a8e1af99fb7cd616d0f3a5b.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_GRADE1_RAISIN_GRADE1_726_jpg.rf.17c1f4559229613b2e47e3de9583dcec.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_GRADE1_RAISIN_GRADE1_726_jpg.rf.fe8bc783a94f8cec0969e0d6c8ca910c.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_GRADE1_RAISIN_GRADE1_886_jpg.rf.2a97d9462f269b2737db870de6fca92a.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_GRADE1_RAISIN_GRADE1_886_jpg.rf.b4eb62751e4b686d4e435be583e5e53f.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_GRADE1_RAISIN_GRADE1_886_jpg.rf.e2258b514ee2fe4eecd40634ba9db789.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_186_jpg.rf.7ee140a9856360d442825fbac08b3c81.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_186_jpg.rf.843161b2e6193dccbe3a7a07085c86ab.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_186_jpg.rf.fbf52ec6aec68c4d893d9232b286e47e.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_244_jpg.rf.9d21239b73413e959786edbda5bc7d33.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_244_jpg.rf.c2e9ba10634ad14e4d1daffc6272e83a.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_244_jpg.rf.cff95e0fd48166ac8d2450f7c9bd5ded.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_256_jpg.rf.2931167a61f7f76a18fc5023b50bbc49.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_256_jpg.rf.4761b0732fc8eb1315a1ceca83493bd1.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_256_jpg.rf.5b003b5a5381f9b31216ef2cda6de507.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_25_jpg.rf.8e70c776dae5fc448c46390b3bcc5fc0.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_25_jpg.rf.c192f4f3bfa065353edd3bf7c76f9c1c.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_25_jpg.rf.d86474239d700460204d898a0dcd5fb1.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_73_jpg.rf.03fb4214a08280a0998085546e43c364.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_73_jpg.rf.468f1f8dee3c89cdeb83786bd60830b8.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_73_jpg.rf.50e8b7bf0cfa13dc88f82f6f04c37830.jpg  \n",
            "  inflating: /content/DryFruits-Segmentation.v2i.coco/train/_annotations.coco.json  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/a-single-grape-on-a-white-wall-photo_webp.rf.1637c610f72c92f88de988c44c64e893.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/a-single-grape-on-a-white-wall-photo_webp.rf.a7a942eeb0cb38cc16dd980ad6e33ded.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/a-single-grape-on-a-white-wall-photo_webp.rf.fed4e6c6291c2d1e838afedfe9e74acd.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/four-concord-grapes-isolated-on-white_webp.rf.3e50126e9b104f04a18d28d911dc480e.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/four-concord-grapes-isolated-on-white_webp.rf.bc9996a038f6cd0fb6155fce2d520dfd.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/four-concord-grapes-isolated-on-white_webp.rf.f21dccb94874eb1b0dca2d2639ae2112.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/front-view-of-fresh-red-grapes-with-half-in-stack-isolated-on-white-background-with-clipping-path-photo_webp.rf.3cbcc297588d495428430d3057276250.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/front-view-of-fresh-red-grapes-with-half-in-stack-isolated-on-white-background-with-clipping-path-photo_webp.rf.626a69badbc02c4899218d8d1734226f.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/front-view-of-fresh-red-grapes-with-half-in-stack-isolated-on-white-background-with-clipping-path-photo_webp.rf.d50352a9cf2bd68cf256f6efb7dc93b6.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/green-grape-isolated-on-white_webp.rf.54c5adfd59edf49eb6e91cd54f23f0ec.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/green-grape-isolated-on-white_webp.rf.599cfee23d4dd175c1b8febec2661efe.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/green-grape-isolated-on-white_webp.rf.e7943b4ca8133d12f2aac688f074297a.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/high-angle-view-grapes-white-fabric_1048944-17885048_webp.rf.1352ce36aa97622579ea6065fb0c00c5.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/high-angle-view-grapes-white-fabric_1048944-17885048_webp.rf.7fefe4af0f990b6fddacca31e202a9e4.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/high-angle-view-grapes-white-fabric_1048944-17885048_webp.rf.d18c8b2a8a41ddd8eefe6d0b2b9ca1d9.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/one-purple-grape-isolated-on-a-black-background-showing-the-details-of-the-skin-and-texture-free-photo_webp.rf.57d038eea28548a402b0e70f81d62629.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/one-purple-grape-isolated-on-a-black-background-showing-the-details-of-the-skin-and-texture-free-photo_webp.rf.d49dbd01734b5c8662f254e29e23da49.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/one-purple-grape-isolated-on-a-black-background-showing-the-details-of-the-skin-and-texture-free-photo_webp.rf.d5e700f0d4937a3fca990a885450970b.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/red-grape-macro_webp.rf.4ba427e382bb967dafe281cf8fa1dbbb.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/red-grape-macro_webp.rf.9521ffc4d9581c831753bb2d8f63f96d.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/red-grape-macro_webp.rf.a9849175e49eac8f958ae1d558710933.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/red-grape-on-white-background-close-up-free-photo_webp.rf.021a3d597bf2284211a726c4146559fd.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/red-grape-on-white-background-close-up-free-photo_webp.rf.594859fd77207bc016e53bcf621d713e.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/red-grape-on-white-background-close-up-free-photo_webp.rf.e676e0bb8d24e4ae36c6531fb62ceee2.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/red-seedless-grape_webp.rf.2fe076374a5322a95e7cde533dfd0370.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/red-seedless-grape_webp.rf.4a46b99346a3e4e47bc05f4ecc260f5f.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/red-seedless-grape_webp.rf.54e90328aba0d280260f204551990bd7.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ripe-red-grape-one-berry-260nw-503311102_webp.rf.3842743cb93e089eec09c2f813de4b4a.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ripe-red-grape-one-berry-260nw-503311102_webp.rf.81a122409e6bcd2e0cd87c3b35f511f4.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ripe-red-grape-one-berry-260nw-503311102_webp.rf.f974995ca7bd03a94997ae4c5fece5b0.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/single-blue-grape-stem-isolated-260nw-152226398_webp.rf.36a074eb01549986b39727ba01ccfd84.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/single-blue-grape-stem-isolated-260nw-152226398_webp.rf.905074fa2de24330f6bdbcb0376b95e3.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/single-blue-grape-stem-isolated-260nw-152226398_webp.rf.a96f85785a88f5fc940149540f1f33d2.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/single-red-grape_webp.rf.5565292c9dd192163de63d574e844592.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/single-red-grape_webp.rf.6ec9a6baad564169f549ed5f2bc8f0af.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/single-red-grape_webp.rf.ebed73d295c6390c0e90c2934c9e0bb6.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/white-grapes_webp.rf.48ea747c09c057c4892483c720763ba5.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/white-grapes_webp.rf.b2fd4fc43fdaf18ca653cb047f243653.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/white-grapes_webp.rf.cd9eeb110c95b184451fef7dc486da3c.jpg  \n",
            "   creating: /content/DryFruits-Segmentation.v2i.coco/valid/\n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/valid/360_F_1218179377_guXOLpOhmvKU3CIiq9HuduiE1PWsofRu_webp.rf.20afe6835a63eaaf3c909d837d26cac0.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/valid/ALMOND_MAMRA_ALMOND_MAMRA_225_jpg.rf.3dcaa22b921ce8a1544a3fd11240b53c.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/valid/ALMOND_MAMRA_ALMOND_MAMRA_470_jpg.rf.6e77c73a1e5fc99c395490e34cc990e6.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/valid/ALMOND_MAMRA_ALMOND_MAMRA_7_jpg.rf.1156fad4657f61ea5443097fbae10e85.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/valid/ALMOND_REGULAR_ALMOND_REGULAR_578_jpg.rf.42471a772eaca2d304a3dc3d5bdc9da2.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/valid/ALMOND_SANORA_ALMOND_SANORA_429_jpg.rf.c40be853c3e3f3817db0be7a2f8109f8.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/valid/ALMOND_SANORA_ALMOND_SANORA_42_jpg.rf.8938726fc836a3f4a62226fc3b478642.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/valid/CASHEW_JUMBO_CASHEW_JUMBO_546_jpg.rf.c9bded083b5400cc729f4a4488633fed.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/valid/CASHEW_REGULAR_CASHEW_REGULAR_357_jpg.rf.0d84526d7e8363bf57803bc3ea4ad29f.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/valid/CASHEW_REGULAR_CASHEW_REGULAR_947_jpg.rf.0b001b5c3c102ebe0fa647ef4c30d0f5.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/valid/RAISIN_BLACK_RAISIN_BLACK_246_jpg.rf.7e8e786f6ff7b85d0b3de664c5309aeb.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/valid/RAISIN_GRADE1_RAISIN_GRADE1_258_jpg.rf.438b1b1360a04ccc905f0c9c8fb33e13.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/valid/RAISIN_GRADE1_RAISIN_GRADE1_421_jpg.rf.9d527a8ef3910fed3b6292e65ac4c08a.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/valid/RAISIN_GRADE1_RAISIN_GRADE1_77_jpg.rf.24ff7564b65216128730e3d4abc2ac6d.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/valid/RAISIN_PREMIUM_RAISIN_PREMIUM_164_jpg.rf.319366a9b055aa34a25aec7b3cb545d2.jpg  \n",
            "  inflating: /content/DryFruits-Segmentation.v2i.coco/valid/_annotations.coco.json  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/valid/black-grapes-isolated-on-white-background-photo_webp.rf.73051d3c82071a4e0ac0a38555e4bb83.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/valid/picture-with-a-fresh-red-grape_webp.rf.80a439b7c124835ffa767ff2ad454059.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/valid/ripe-red-grape-isolated-on-white-with-clipping-path-full-depth-of-field_webp.rf.1dc6409b9f990327718501bbe6e2bd62.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/valid/two-purple-grapes-with-green-stems_webp.rf.dec748accae0914de4ab7c0cba1abe7d.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/valid/wet-grape-on-white-background_webp.rf.ae3299c74d1755af68f89158458320e2.jpg  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/DryFruits-classification.v1i.coco\""
      ],
      "metadata": {
        "id": "xlNOfxafVKz7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset_dir(dataset_path)"
      ],
      "metadata": {
        "id": "Q1z_RhTUVh-z"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, val_dataset, test_dataset = dataset.create_custom_datasets(ToTensor, segmentation=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzhH-2VdVkLK",
        "outputId": "c2a4a9b5-fb12-48c2-9002-5082712e534d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_loader, val_data_loader, test_data_loader = CustomDataLoader(train_dataset, val_dataset, test_dataset, batch_size).create_data_loader()"
      ],
      "metadata": {
        "id": "2OqHTKboYA6n"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dry_fruit_detection_segmentation.utils import FocalLoss, custom_fastrcnn_loss, get_segmentation_model"
      ],
      "metadata": {
        "id": "EBwaEGtMROoZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extra class; for background\n",
        "num_classes = len(train_dataset.coco.getCatIds()) + 1\n",
        "model = get_detection_model(num_classes, mobilenet=True, custom_focal_loss=False)\n",
        "\n",
        "# move model to the right device\n",
        "model.to(device)\n",
        "\n",
        "# parameters\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "\n",
        "num_epochs = 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfB3jR4ZdAUG",
        "outputId": "c3597c21-5a1d-4eba-acb5-df5a74ed9421"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_MobileNet_V3_Large_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_MobileNet_V3_Large_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/fasterrcnn_mobilenet_v3_large_fpn-fb6a3cc7.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_mobilenet_v3_large_fpn-fb6a3cc7.pth\n",
            "100%|| 74.2M/74.2M [00:00<00:00, 101MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_map = 0.0\n",
        "epochs_no_improve = 0\n",
        "patience = 5  # stop if no improvement for 5 consecutive epochs\n",
        "save_path = \"mobilenet_v1.pth\""
      ],
      "metadata": {
        "id": "czS89_JUdGgH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(num_epochs, train_data_loader, model, val_data_loader, convert_to_coco_format, dataset\n",
        ", device, optimizer, save_path, patience=5, best_map=0.0, segmentation=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUjvwUsykDoa",
        "outputId": "fe711bb4-8b66-4f22-9bad-7e39eaf25be3",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|| 18/18 [00:02<00:00,  6.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1] Training Loss: 1.9449\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|| 5/5 [00:00<00:00, 12.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "[Epoch 1] Evaluation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.318\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.605\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.355\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.318\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.548\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.548\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.548\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.548\n",
            "New best mAP: 0.3182 (previous best: 0.0000)  saving model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 2: 100%|| 18/18 [00:02<00:00,  7.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 2] Training Loss: 1.6150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|| 5/5 [00:00<00:00, 12.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            "[Epoch 2] Evaluation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.392\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.749\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.353\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.392\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.572\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.572\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.572\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.572\n",
            "New best mAP: 0.3925 (previous best: 0.3182)  saving model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 3: 100%|| 18/18 [00:02<00:00,  7.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 3] Training Loss: 1.3147\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|| 5/5 [00:00<00:00, 12.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "[Epoch 3] Evaluation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.506\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.806\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.615\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.506\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.639\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.639\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.639\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.639\n",
            "New best mAP: 0.5057 (previous best: 0.3925)  saving model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 4: 100%|| 18/18 [00:02<00:00,  7.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 4] Training Loss: 0.7642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|| 5/5 [00:00<00:00, 11.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.02s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            "[Epoch 4] Evaluation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.563\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.791\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.731\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.563\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.676\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.676\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.676\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.676\n",
            "New best mAP: 0.5630 (previous best: 0.5057)  saving model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 5: 100%|| 18/18 [00:02<00:00,  6.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 5] Training Loss: 0.7577\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|| 5/5 [00:00<00:00, 12.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "[Epoch 5] Evaluation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.561\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.821\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.679\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.561\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.693\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.693\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.693\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.693\n",
            "No improvement in mAP for 1 epoch(s).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 6: 100%|| 18/18 [00:02<00:00,  7.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 6] Training Loss: 0.6209\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|| 5/5 [00:00<00:00, 12.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "[Epoch 6] Evaluation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.579\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.866\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.672\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.579\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.654\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.654\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.654\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.654\n",
            "New best mAP: 0.5785 (previous best: 0.5630)  saving model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 7: 100%|| 18/18 [00:02<00:00,  7.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 7] Training Loss: 0.8513\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|| 5/5 [00:00<00:00, 12.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "[Epoch 7] Evaluation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.646\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.859\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.804\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.646\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.725\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.725\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.725\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.725\n",
            "New best mAP: 0.6456 (previous best: 0.5785)  saving model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 8: 100%|| 18/18 [00:02<00:00,  7.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 8] Training Loss: 0.6874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|| 5/5 [00:00<00:00, 10.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.02s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            "[Epoch 8] Evaluation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.600\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.849\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.751\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.600\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.691\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.691\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.691\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.691\n",
            "No improvement in mAP for 1 epoch(s).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 9: 100%|| 18/18 [00:02<00:00,  6.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 9] Training Loss: 0.5872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|| 5/5 [00:00<00:00, 12.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            "[Epoch 9] Evaluation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.660\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.888\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.802\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.660\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.735\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.735\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.735\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.735\n",
            "New best mAP: 0.6603 (previous best: 0.6456)  saving model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 10: 100%|| 18/18 [00:02<00:00,  7.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 10] Training Loss: 0.5019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|| 5/5 [00:00<00:00, 11.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.02s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "[Epoch 10] Evaluation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.691\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.863\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.863\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.691\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.764\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.764\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.764\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.764\n",
            "New best mAP: 0.6911 (previous best: 0.6603)  saving model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 11: 100%|| 18/18 [00:02<00:00,  7.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 11] Training Loss: 0.4612\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|| 5/5 [00:00<00:00, 12.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "[Epoch 11] Evaluation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.671\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.863\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.863\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.671\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.756\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.756\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.756\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.756\n",
            "No improvement in mAP for 1 epoch(s).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 12: 100%|| 18/18 [00:02<00:00,  7.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 12] Training Loss: 0.5164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|| 5/5 [00:00<00:00, 12.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.02s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            "[Epoch 12] Evaluation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.621\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.814\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.814\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.621\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.706\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.706\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.706\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.706\n",
            "No improvement in mAP for 2 epoch(s).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 13: 100%|| 18/18 [00:02<00:00,  6.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 13] Training Loss: 0.4963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|| 5/5 [00:00<00:00, 11.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "[Epoch 13] Evaluation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.666\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.862\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.816\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.666\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.749\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.749\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.749\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.749\n",
            "No improvement in mAP for 3 epoch(s).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 14: 100%|| 18/18 [00:02<00:00,  7.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 14] Training Loss: 0.5050\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|| 5/5 [00:00<00:00, 12.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "[Epoch 14] Evaluation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.653\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.861\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.861\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.653\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.735\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.735\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.735\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.735\n",
            "No improvement in mAP for 4 epoch(s).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 15: 100%|| 18/18 [00:02<00:00,  7.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 15] Training Loss: 0.4489\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|| 5/5 [00:00<00:00, 11.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "[Epoch 15] Evaluation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.726\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.867\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.867\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.726\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.812\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.812\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.812\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.812\n",
            "New best mAP: 0.7259 (previous best: 0.6911)  saving model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 16: 100%|| 18/18 [00:02<00:00,  7.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 16] Training Loss: 0.3745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|| 5/5 [00:00<00:00, 12.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "[Epoch 16] Evaluation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.726\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.853\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.853\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.726\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.778\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.778\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.778\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.778\n",
            "New best mAP: 0.7264 (previous best: 0.7259)  saving model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 17: 100%|| 18/18 [00:02<00:00,  6.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 17] Training Loss: 0.3996\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|| 5/5 [00:00<00:00, 12.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "[Epoch 17] Evaluation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.693\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.864\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.864\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.693\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.781\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.781\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.781\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.781\n",
            "No improvement in mAP for 1 epoch(s).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 18: 100%|| 18/18 [00:02<00:00,  7.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 18] Training Loss: 0.5522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|| 5/5 [00:00<00:00, 12.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            "[Epoch 18] Evaluation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.668\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.868\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.868\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.668\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.766\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.766\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.766\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.766\n",
            "No improvement in mAP for 2 epoch(s).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 19: 100%|| 18/18 [00:02<00:00,  7.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 19] Training Loss: 0.4541\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|| 5/5 [00:00<00:00, 12.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "[Epoch 19] Evaluation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.651\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.853\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.853\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.651\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.719\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.719\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.719\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.719\n",
            "No improvement in mAP for 3 epoch(s).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 20: 100%|| 18/18 [00:02<00:00,  7.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 20] Training Loss: 0.3669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|| 5/5 [00:00<00:00, 12.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            "[Epoch 20] Evaluation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.691\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.853\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.853\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.691\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.743\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.743\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.743\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.743\n",
            "No improvement in mAP for 4 epoch(s).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 21: 100%|| 18/18 [00:02<00:00,  6.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 21] Training Loss: 0.3550\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|| 5/5 [00:00<00:00, 11.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "[Epoch 21] Evaluation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.722\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.886\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.886\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.722\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.790\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.790\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.790\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.790\n",
            "No improvement in mAP for 5 epoch(s).\n",
            "Early stopping triggered after 21 epochs. Best mAP: 0.7264\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "create_video_from_images(dataset.test_dir, \"object_detection_in.mp4\", fps=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "024UVZPjA31R",
        "outputId": "8157539c-69ec-4339-a69f-63880da6ca8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video saved to object_detection_in.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_segmentation_model(num_classes, custom_focal_loss=False)\n",
        "model.load_state_dict(torch.load(\"segmentation_v1.pth\"))\n",
        "model.to(device)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rfOWjL0ABLpN",
        "outputId": "f21a9f77-7a50-49e8-867d-1176f333437f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MaskRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=MaskRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MaskRCNN(\n",
              "  (transform): GeneralizedRCNNTransform(\n",
              "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
              "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
              "  )\n",
              "  (backbone): BackboneWithFPN(\n",
              "    (body): IntermediateLayerGetter(\n",
              "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (layer1): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer2): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer3): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (4): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (5): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer4): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (fpn): FeaturePyramidNetwork(\n",
              "      (inner_blocks): ModuleList(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (2): Conv2dNormActivation(\n",
              "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (layer_blocks): ModuleList(\n",
              "        (0-3): 4 x Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (extra_blocks): LastLevelMaxPool()\n",
              "    )\n",
              "  )\n",
              "  (rpn): RegionProposalNetwork(\n",
              "    (anchor_generator): AnchorGenerator()\n",
              "    (head): RPNHead(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (roi_heads): RoIHeads(\n",
              "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
              "    (box_head): TwoMLPHead(\n",
              "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
              "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    )\n",
              "    (box_predictor): FastRCNNPredictor(\n",
              "      (cls_score): Linear(in_features=1024, out_features=6, bias=True)\n",
              "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
              "    )\n",
              "    (mask_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(14, 14), sampling_ratio=2)\n",
              "    (mask_head): MaskRCNNHeads(\n",
              "      (0): Conv2dNormActivation(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (1): Conv2dNormActivation(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Conv2dNormActivation(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Conv2dNormActivation(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (mask_predictor): MaskRCNNPredictor(\n",
              "      (conv5_mask): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (mask_fcn_logits): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id_to_name = {\n",
        "    1: \"almond\",\n",
        "    2: \"cashew\",\n",
        "    3: \"grapes\",\n",
        "    4: \"raisin\"\n",
        "}"
      ],
      "metadata": {
        "id": "mh-b7Fq7BPsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_img = \"/360_F_1248363446_QWsdjuZlE2uK4sg1gCZSMogHM5d5SDqv_webp.rf.98746b3d6b7cd7d53599adf17435b3ff.jpg\""
      ],
      "metadata": {
        "id": "m1Q_4eADCbTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dry_fruit_detection_segmentation.utils import save_predicted_image, save_predicted_video"
      ],
      "metadata": {
        "id": "SilQgndQCFpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dry_fruit_detection_segmentation.utils import closest_basic_color_name, detect_shape, save_segmented_image"
      ],
      "metadata": {
        "id": "Kc5keEC_hi1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_predicted_image(\"/content/DryFruits-Detection.v2i.coco/test/ALMOND_REGULAR_ALMOND_REGULAR_753_jpg.rf.0fc0280f63ea517a12ddacfa2926d7c2.jpg\", \"output4.jpg\", model, device, id_to_name)"
      ],
      "metadata": {
        "id": "GlNvXOHxCE2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_predicted_video(\"/content/object_detection_in.mp4\", \"segmentation_v1.mp4\", model, device, id_to_name, threshold=0.4)"
      ],
      "metadata": {
        "id": "at8wt_faKRPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_detection_model(num_classes, mobilenet=True, custom_focal_loss=False)\n",
        "model.eval()"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWroqLfrrXfa",
        "outputId": "0ee6cc49-5730-4fb3-a1db-1623ea638451"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FasterRCNN(\n",
              "  (transform): GeneralizedRCNNTransform(\n",
              "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
              "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
              "  )\n",
              "  (backbone): BackboneWithFPN(\n",
              "    (body): IntermediateLayerGetter(\n",
              "      (0): Conv2dNormActivation(\n",
              "        (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (1): FrozenBatchNorm2d(16, eps=1e-05)\n",
              "        (2): Hardswish()\n",
              "      )\n",
              "      (1): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
              "            (1): FrozenBatchNorm2d(16, eps=1e-05)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(16, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(64, eps=1e-05)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
              "            (1): FrozenBatchNorm2d(64, eps=1e-05)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): Conv2dNormActivation(\n",
              "            (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(24, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(72, eps=1e-05)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
              "            (1): FrozenBatchNorm2d(72, eps=1e-05)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): Conv2dNormActivation(\n",
              "            (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(24, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (4): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(72, eps=1e-05)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
              "            (1): FrozenBatchNorm2d(72, eps=1e-05)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Hardsigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(40, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (5): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(120, eps=1e-05)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
              "            (1): FrozenBatchNorm2d(120, eps=1e-05)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Hardsigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(40, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (6): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(120, eps=1e-05)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
              "            (1): FrozenBatchNorm2d(120, eps=1e-05)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Hardsigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(40, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (7): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(240, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
              "            (1): FrozenBatchNorm2d(240, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (2): Conv2dNormActivation(\n",
              "            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(80, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (8): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(200, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
              "            (1): FrozenBatchNorm2d(200, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (2): Conv2dNormActivation(\n",
              "            (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(80, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (9): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(184, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
              "            (1): FrozenBatchNorm2d(184, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (2): Conv2dNormActivation(\n",
              "            (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(80, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (10): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(184, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
              "            (1): FrozenBatchNorm2d(184, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (2): Conv2dNormActivation(\n",
              "            (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(80, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (11): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(480, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "            (1): FrozenBatchNorm2d(480, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Hardsigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(112, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (12): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(672, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
              "            (1): FrozenBatchNorm2d(672, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Hardsigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(112, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (13): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(672, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
              "            (1): FrozenBatchNorm2d(672, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Hardsigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(160, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (14): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(960, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
              "            (1): FrozenBatchNorm2d(960, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Hardsigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(160, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (15): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(960, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
              "            (1): FrozenBatchNorm2d(960, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Hardsigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(160, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (16): Conv2dNormActivation(\n",
              "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): FrozenBatchNorm2d(960, eps=1e-05)\n",
              "        (2): Hardswish()\n",
              "      )\n",
              "    )\n",
              "    (fpn): FeaturePyramidNetwork(\n",
              "      (inner_blocks): ModuleList(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(160, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(960, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (layer_blocks): ModuleList(\n",
              "        (0-1): 2 x Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (extra_blocks): LastLevelMaxPool()\n",
              "    )\n",
              "  )\n",
              "  (rpn): RegionProposalNetwork(\n",
              "    (anchor_generator): AnchorGenerator()\n",
              "    (head): RPNHead(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (cls_logits): Conv2d(256, 15, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bbox_pred): Conv2d(256, 60, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (roi_heads): RoIHeads(\n",
              "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
              "    (box_head): TwoMLPHead(\n",
              "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
              "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    )\n",
              "    (box_predictor): FastRCNNPredictor(\n",
              "      (cls_score): Linear(in_features=1024, out_features=6, bias=True)\n",
              "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"mobilenet_v1.pth\"))\n",
        "\n",
        "# Set to eval mode\n",
        "model.eval()"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCLcnnojtq-a",
        "outputId": "ba7e65f4-d298-40c2-b232-8ce301134075"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FasterRCNN(\n",
              "  (transform): GeneralizedRCNNTransform(\n",
              "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
              "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
              "  )\n",
              "  (backbone): BackboneWithFPN(\n",
              "    (body): IntermediateLayerGetter(\n",
              "      (0): Conv2dNormActivation(\n",
              "        (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (1): FrozenBatchNorm2d(16, eps=1e-05)\n",
              "        (2): Hardswish()\n",
              "      )\n",
              "      (1): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
              "            (1): FrozenBatchNorm2d(16, eps=1e-05)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(16, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(64, eps=1e-05)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
              "            (1): FrozenBatchNorm2d(64, eps=1e-05)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): Conv2dNormActivation(\n",
              "            (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(24, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(72, eps=1e-05)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
              "            (1): FrozenBatchNorm2d(72, eps=1e-05)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): Conv2dNormActivation(\n",
              "            (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(24, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (4): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(72, eps=1e-05)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
              "            (1): FrozenBatchNorm2d(72, eps=1e-05)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Hardsigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(40, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (5): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(120, eps=1e-05)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
              "            (1): FrozenBatchNorm2d(120, eps=1e-05)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Hardsigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(40, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (6): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(120, eps=1e-05)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
              "            (1): FrozenBatchNorm2d(120, eps=1e-05)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Hardsigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(40, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (7): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(240, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
              "            (1): FrozenBatchNorm2d(240, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (2): Conv2dNormActivation(\n",
              "            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(80, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (8): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(200, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
              "            (1): FrozenBatchNorm2d(200, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (2): Conv2dNormActivation(\n",
              "            (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(80, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (9): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(184, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
              "            (1): FrozenBatchNorm2d(184, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (2): Conv2dNormActivation(\n",
              "            (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(80, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (10): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(184, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
              "            (1): FrozenBatchNorm2d(184, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (2): Conv2dNormActivation(\n",
              "            (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(80, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (11): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(480, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "            (1): FrozenBatchNorm2d(480, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Hardsigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(112, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (12): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(672, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
              "            (1): FrozenBatchNorm2d(672, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Hardsigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(112, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (13): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(672, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
              "            (1): FrozenBatchNorm2d(672, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Hardsigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(160, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (14): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(960, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
              "            (1): FrozenBatchNorm2d(960, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Hardsigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(160, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (15): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(960, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
              "            (1): FrozenBatchNorm2d(960, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Hardsigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(160, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (16): Conv2dNormActivation(\n",
              "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): FrozenBatchNorm2d(960, eps=1e-05)\n",
              "        (2): Hardswish()\n",
              "      )\n",
              "    )\n",
              "    (fpn): FeaturePyramidNetwork(\n",
              "      (inner_blocks): ModuleList(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(160, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(960, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (layer_blocks): ModuleList(\n",
              "        (0-1): 2 x Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (extra_blocks): LastLevelMaxPool()\n",
              "    )\n",
              "  )\n",
              "  (rpn): RegionProposalNetwork(\n",
              "    (anchor_generator): AnchorGenerator()\n",
              "    (head): RPNHead(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (cls_logits): Conv2d(256, 15, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bbox_pred): Conv2d(256, 60, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (roi_heads): RoIHeads(\n",
              "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
              "    (box_head): TwoMLPHead(\n",
              "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
              "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    )\n",
              "    (box_predictor): FastRCNNPredictor(\n",
              "      (cls_score): Linear(in_features=1024, out_features=6, bias=True)\n",
              "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision onnx tf2onnx onnx-tf tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wjD2NiAlutPj",
        "outputId": "71b21bc4-a81c-4eff-cc3e-e7576d3f1fb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting tf2onnx\n",
            "  Downloading tf2onnx-1.16.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting onnx-tf\n",
            "  Downloading onnx_tf-1.10.0-py3-none-any.whl.metadata (510 bytes)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (5.29.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from tf2onnx) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from tf2onnx) (1.17.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.11/dist-packages (from tf2onnx) (25.2.10)\n",
            "INFO: pip is looking at multiple versions of tf2onnx to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tf2onnx\n",
            "  Downloading tf2onnx-1.16.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "  Downloading tf2onnx-1.15.1-py3-none-any.whl.metadata (1.2 kB)\n",
            "  Downloading tf2onnx-1.15.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting flatbuffers<3.0,>=1.12 (from tf2onnx)\n",
            "  Downloading flatbuffers-2.0.7-py2.py3-none-any.whl.metadata (872 bytes)\n",
            "Collecting tf2onnx\n",
            "  Downloading tf2onnx-1.14.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from onnx-tf) (6.0.2)\n",
            "Collecting tensorflow-addons (from onnx-tf)\n",
            "  Downloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "INFO: pip is looking at multiple versions of tensorflow to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "  Downloading tensorflow-2.18.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "  Downloading tensorflow-2.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "  Downloading tensorflow-2.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "  Downloading tensorflow-2.16.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "  Downloading tensorflow-2.16.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "  Downloading tensorflow-2.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "INFO: pip is still looking at multiple versions of tensorflow to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading tensorflow-2.15.0.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "  Downloading tensorflow-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "  Downloading tensorflow-2.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "  Downloading tensorflow-2.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "  Downloading tensorflow-2.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading tensorflow-2.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "  Downloading tensorflow-2.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.2)\n",
            "Collecting keras<2.13,>=2.12.0 (from tensorflow)\n",
            "  Downloading keras-2.12.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Collecting numpy (from torchvision)\n",
            "  Downloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Collecting protobuf>=4.25.1 (from onnx)\n",
            "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Collecting tensorboard<2.13,>=2.12 (from tensorflow)\n",
            "  Downloading tensorboard-2.12.3-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow)\n",
            "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting numpy (from torchvision)\n",
            "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow)\n",
            "  Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: jaxlib<=0.5.2,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow) (0.4.1)\n",
            "INFO: pip is looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jax>=0.3.15 (from tensorflow)\n",
            "  Downloading jax-0.6.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib<=0.6.1,>=0.6.1 (from jax>=0.3.15->tensorflow)\n",
            "  Downloading jaxlib-0.6.1-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting ml_dtypes>=0.5.0 (from jax>=0.3.15->tensorflow)\n",
            "  Downloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow)\n",
            "  Downloading jax-0.6.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.6.0,>=0.6.0 (from jax>=0.3.15->tensorflow)\n",
            "  Downloading jaxlib-0.6.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow)\n",
            "  Downloading jax-0.5.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.5.3,>=0.5.3 (from jax>=0.3.15->tensorflow)\n",
            "  Downloading jaxlib-0.5.3-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow)\n",
            "  Downloading jax-0.5.1-py3-none-any.whl.metadata (22 kB)\n",
            "  Downloading jax-0.5.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.5.0,>=0.5.0 (from jax>=0.3.15->tensorflow)\n",
            "  Downloading jaxlib-0.5.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (978 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow)\n",
            "  Downloading jax-0.4.38-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.38,>=0.4.38 (from jax>=0.3.15->tensorflow)\n",
            "  Downloading jaxlib-0.4.38-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow)\n",
            "  Downloading jax-0.4.37-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.37,>=0.4.36 (from jax>=0.3.15->tensorflow)\n",
            "  Downloading jaxlib-0.4.36-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "INFO: pip is still looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jax>=0.3.15 (from tensorflow)\n",
            "  Downloading jax-0.4.36-py3-none-any.whl.metadata (22 kB)\n",
            "  Downloading jax-0.4.35-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.35,>=0.4.34 (from jax>=0.3.15->tensorflow)\n",
            "  Downloading jaxlib-0.4.35-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow)\n",
            "  Downloading jax-0.4.34-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.34,>=0.4.34 (from jax>=0.3.15->tensorflow)\n",
            "  Downloading jaxlib-0.4.34-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow)\n",
            "  Downloading jax-0.4.33-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.33,>=0.4.33 (from jax>=0.3.15->tensorflow)\n",
            "  Downloading jaxlib-0.4.33-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow)\n",
            "  Downloading jax-0.4.31-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.31,>=0.4.30 (from jax>=0.3.15->tensorflow)\n",
            "  Downloading jaxlib-0.4.31-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting jax>=0.3.15 (from tensorflow)\n",
            "  Downloading jax-0.4.30-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.30,>=0.4.27 (from jax>=0.3.15->tensorflow)\n",
            "  Downloading jaxlib-0.4.30-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow) (1.15.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.38.0)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.13,>=2.12->tensorflow)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->tf2onnx) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->tf2onnx) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->tf2onnx) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->tf2onnx) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons->onnx-tf)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m90.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m107.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tf2onnx-1.14.0-py3-none-any.whl (451 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m451.2/451.2 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx_tf-1.10.0-py3-none-any.whl (226 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m226.1/226.1 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (586.0 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m586.0/586.0 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flatbuffers-2.0.7-py2.py3-none-any.whl (26 kB)\n",
            "Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Downloading jax-0.4.30-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m111.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m117.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading jaxlib-0.4.30-cp311-cp311-manylinux2014_x86_64.whl (79.6 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m79.6/79.6 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: flatbuffers, wrapt, typeguard, tensorflow-estimator, protobuf, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, keras, gast, tensorflow-addons, onnx, nvidia-cusparse-cu12, nvidia-cudnn-cu12, tf2onnx, onnx-tf, nvidia-cusolver-cu12, jaxlib, google-auth-oauthlib, tensorboard, jax, tensorflow\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 25.2.10\n",
            "    Uninstalling flatbuffers-25.2.10:\n",
            "      Successfully uninstalled flatbuffers-25.2.10\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 4.4.2\n",
            "    Uninstalling typeguard-4.4.2:\n",
            "      Successfully uninstalled typeguard-4.4.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.8.0\n",
            "    Uninstalling keras-3.8.0:\n",
            "      Successfully uninstalled keras-3.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.6.0\n",
            "    Uninstalling gast-0.6.0:\n",
            "      Successfully uninstalled gast-0.6.0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.5.1\n",
            "    Uninstalling jaxlib-0.5.1:\n",
            "      Successfully uninstalled jaxlib-0.5.1\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.2\n",
            "    Uninstalling google-auth-oauthlib-1.2.2:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.2\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.5.2\n",
            "    Uninstalling jax-0.5.2:\n",
            "      Successfully uninstalled jax-0.5.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.18.0\n",
            "    Uninstalling tensorflow-2.18.0:\n",
            "      Successfully uninstalled tensorflow-2.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 2.0.7 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "db-dtypes 1.4.3 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "albucore 0.0.24 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "flax 0.10.6 requires jax>=0.5.1, but you have jax 0.4.30 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "blosc2 3.3.3 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "ydf 0.12.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "bigframes 2.4.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "pymc 5.22.0 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.23.5 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "xarray 2025.3.1 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "orbax-checkpoint 0.11.13 requires jax>=0.5.0, but you have jax 0.4.30 which is incompatible.\n",
            "inflect 7.5.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.12.0 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed flatbuffers-2.0.7 gast-0.4.0 google-auth-oauthlib-1.0.0 jax-0.4.30 jaxlib-0.4.30 keras-2.12.0 numpy-1.23.5 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 onnx-1.18.0 onnx-tf-1.10.0 protobuf-4.25.8 tensorboard-2.12.3 tensorflow-2.12.0 tensorflow-addons-0.23.0 tensorflow-estimator-2.12.0 tf2onnx-1.14.0 typeguard-2.13.3 wrapt-1.14.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "b8a31cf610c14631b44a50619c71cef0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "\n",
        "image = Image.open(\"/content/DryFruits-classification.v1i.coco/test/ALMOND_REGULAR_ALMOND_REGULAR_753_jpg.rf.0fc0280f63ea517a12ddacfa2926d7c2.jpg\").convert(\"RGB\")\n",
        "transform = T.ToTensor()\n",
        "tensor_img = transform(image).unsqueeze(0)  # shape: (1, 3, H, W)\n",
        "\n",
        "print(tensor_img.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmFj-0G0r24C",
        "outputId": "33def0d2-f2eb-401b-a634-36bcf3933499"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 640, 640])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# In put shape - ([1, 3, 640, 640])"
      ],
      "metadata": {
        "id": "xGmlvsHetUHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_input = torch.randn(1, 3, 640, 640)\n",
        "\n",
        "torch.onnx.export(model, dummy_input, \"mobilenet_v1.onnx\",\n",
        "                  input_names=['input'], output_names=['output'],\n",
        "                  dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}})"
      ],
      "metadata": {
        "id": "drtiYQ-3vk5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxruntime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7-2pASAxmLt",
        "outputId": "49f81669-cb0b-4477-c20d-9dc82f281586"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (2.0.7)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (4.25.8)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m106.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.22.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime as ort\n",
        "import numpy as np\n",
        "\n",
        "session = ort.InferenceSession(\"mobilenet_v1.onnx\")\n",
        "outputs = session.run(None, {\"input\": np.random.randn(1, 3, 640, 640).astype(np.float32)})\n",
        "\n",
        "print(outputs)  # should print boxes, labels, scores, masks\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3m2TKDxtRhr",
        "outputId": "b1f52b23-1daf-41a4-b8ea-848dafaf8d72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([], shape=(0, 4), dtype=float32), array([], dtype=int64), array([], dtype=float32)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from torchvision.transforms import functional as F\n",
        "\n",
        "# Load and preprocess image\n",
        "image = cv2.imread(dataset.test_dir+example_img)\n",
        "image = cv2.resize(image, (640, 640))\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Normalize and convert to tensor\n",
        "image_tensor = F.to_tensor(image_rgb).unsqueeze(0).numpy().astype(np.float32)\n",
        "\n",
        "outputs = session.run(None, {\"input\": image_tensor})\n",
        "print(outputs)\n"
      ],
      "metadata": {
        "id": "kPuW7uULyAJO",
        "outputId": "e0e557aa-826e-4e66-f653-677029452ea1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeException",
          "evalue": "[ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Non-zero status code returned while running Reshape node. Name:'/roi_heads/Reshape_2' Status Message: /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/reshape_helper.h:39 onnxruntime::ReshapeHelper::ReshapeHelper(const onnxruntime::TensorShape&, onnxruntime::TensorShapeVector&, bool) size != 0 && (input_shape_size % size) == 0 was false. The input tensor cannot be reshaped to the requested shape. Input shape:{82,23}, requested shape:{-1,4}\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeException\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-9ad79d0837a6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mimage_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_rgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"input\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage_tensor\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0moutput_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_meta\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_feed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPFail\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_fallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeException\u001b[0m: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Non-zero status code returned while running Reshape node. Name:'/roi_heads/Reshape_2' Status Message: /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/reshape_helper.h:39 onnxruntime::ReshapeHelper::ReshapeHelper(const onnxruntime::TensorShape&, onnxruntime::TensorShapeVector&, bool) size != 0 && (input_shape_size % size) == 0 was false. The input tensor cannot be reshaped to the requested shape. Input shape:{82,23}, requested shape:{-1,4}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Dummy input image\n",
        "dummy_image = torch.rand(1, 3, 640, 640)  # [B, C, H, W]\n",
        "torch.onnx.export(\n",
        "    model_frcnn,\n",
        "    (dummy_image,),\n",
        "    \"fasterrcnn.onnx\",\n",
        "    input_names=[\"input\"],\n",
        "    output_names=[\"boxes\", \"labels\", \"scores\"],\n",
        "    dynamic_axes={\"input\": {0: \"batch_size\"}},\n",
        "    opset_version=11,\n",
        ")\n",
        "print(\"[] Exported Faster R-CNN to ONNX\")\n"
      ],
      "metadata": {
        "id": "WeYD3AZErl7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MaskRCNNWrapper(nn.Module):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "\n",
        "    def forward(self, x):\n",
        "        outputs = self.model(x)\n",
        "        boxes = outputs[0][\"boxes\"]\n",
        "        labels = outputs[0][\"labels\"]\n",
        "        scores = outputs[0][\"scores\"]\n",
        "        masks = outputs[0][\"masks\"]\n",
        "        return boxes, labels, scores, masks\n"
      ],
      "metadata": {
        "id": "3oktuzGVsnGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class FasterRCNNWrapper(nn.Module):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "\n",
        "    def forward(self, x):\n",
        "        outputs = self.model(x)\n",
        "        boxes = outputs[0][\"boxes\"]\n",
        "        labels = outputs[0][\"labels\"]\n",
        "        scores = outputs[0][\"scores\"]\n",
        "        return boxes, labels, scores\n"
      ],
      "metadata": {
        "id": "_4BF6P0Tsph2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wrapped_model = FasterRCNNWrapper(model)\n",
        "wrapped_model.eval()\n",
        "\n",
        "torch.onnx.export(\n",
        "    wrapped_model,\n",
        "    dummy_input,\n",
        "    \"fasterrcnn_model.onnx\",\n",
        "    export_params=True,\n",
        "    opset_version=11,\n",
        "    input_names=[\"input\"],\n",
        "    output_names=[\"boxes\", \"labels\", \"scores\"],\n",
        "    dynamic_axes={\n",
        "        \"input\": {0: \"batch_size\"},\n",
        "        \"boxes\": {0: \"batch_size\"},\n",
        "        \"labels\": {0: \"batch_size\"},\n",
        "        \"scores\": {0: \"batch_size\"},\n",
        "    }\n",
        ")\n"
      ],
      "metadata": {
        "id": "QRZDRF_vsr2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wrapped_model = MaskRCNNWrapper(model)\n",
        "wrapped_model.eval()\n",
        "\n",
        "dummy_input = torch.randn(1, 3, 512, 512)  # match your actual input shape\n",
        "\n",
        "torch.onnx.export(\n",
        "    wrapped_model,\n",
        "    dummy_input,\n",
        "    \"maskrcnn_model.onnx\",\n",
        "    export_params=True,\n",
        "    opset_version=11,\n",
        "    input_names=[\"input\"],\n",
        "    output_names=[\"boxes\", \"labels\", \"scores\", \"masks\"],\n",
        "    dynamic_axes={\n",
        "        \"input\": {0: \"batch_size\"},\n",
        "        \"boxes\": {0: \"batch_size\"},\n",
        "        \"labels\": {0: \"batch_size\"},\n",
        "        \"scores\": {0: \"batch_size\"},\n",
        "        \"masks\": {0: \"batch_size\"},\n",
        "    }\n",
        ")\n"
      ],
      "metadata": {
        "id": "Av-pJG7ctRo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "validation"
      ],
      "metadata": {
        "id": "qTwZ4NLxtiYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "\n",
        "mobilenet = models.mobilenet_v2(pretrained=True)\n",
        "mobilenet.eval()\n",
        "\n",
        "dummy_input = torch.randn(1, 3, 224, 224)\n",
        "\n",
        "torch.onnx.export(mobilenet, dummy_input, \"mobilenet_v2.onnx\",\n",
        "                  input_names=['input'], output_names=['output'],\n",
        "                  dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}})\n"
      ],
      "metadata": {
        "id": "ep4RH3MauaB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install onnx-tf tensorflow"
      ],
      "metadata": {
        "id": "yHRypcaSud07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert ONNX to TensorFlow\n",
        "from onnx_tf.backend import prepare\n",
        "import onnx\n",
        "\n",
        "onnx_model = onnx.load(\"mobilenet_v2.onnx\")\n",
        "tf_rep = prepare(onnx_model)\n",
        "tf_rep.export_graph(\"mobilenet_tf\")\n",
        "\n",
        "# Convert TensorFlow to TFLite\n",
        "import tensorflow as tf\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(\"mobilenet_tf\")\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open(\"mobilenet.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)\n"
      ],
      "metadata": {
        "id": "1YDMxxphulhr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}