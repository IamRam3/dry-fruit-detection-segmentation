{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IamRam3/dry-fruit-detection-segmentation/blob/main/test_modularity_(dryfruits)_v0_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvQ44_lzh4nj"
      },
      "source": [
        "#Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBDxZggPTPBE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from PIL import Image\n",
        "from pycocotools.coco import COCO\n",
        "import torch.utils.data\n",
        "import torchvision\n",
        "from torchvision.transforms import ToTensor\n",
        "from pycocotools.cocoeval import COCOeval\n",
        "import json\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hmBZl_RERFjL",
        "outputId": "0b5d1fc8-f21a-452b-a996-2e702d290bae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'dry-fruit-detection-segmentation' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/IamRam3/dry-fruit-detection-segmentation.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxbNgGRtUUou",
        "outputId": "b9981b86-7034-49b2-f1c5-217bd0fc9fb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mv: cannot move 'dry-fruit-detection-segmentation' to 'dry_fruit_detection_segmentation/dry-fruit-detection-segmentation': Directory not empty\n"
          ]
        }
      ],
      "source": [
        "!mv dry-fruit-detection-segmentation dry_fruit_detection_segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMiZy9n0T8Bn"
      },
      "outputs": [],
      "source": [
        "#!rm -rf dry_fruit_detection_segmentation/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "To-3MYjlTRJ_"
      },
      "outputs": [],
      "source": [
        "from dry_fruit_detection_segmentation.src.data_setup import CocoDataset, coco_dataset_dir, CustomDataLoader\n",
        "from dry_fruit_detection_segmentation.utils import get_transform, convert_to_coco_format, get_detection_model, train_pipe, create_video_from_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R21ExtAETTat"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUD3XBfaTX6r"
      },
      "outputs": [],
      "source": [
        "batch_size=4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "teLk_3ssiHuP",
        "outputId": "c4c66d3c-1f54-4854-d6ee-ad0decb31003"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/dry_fruit_detection_segmentation/datasets/labeled_dataset2/DryFruits-classification.v1i.coco.zip\n",
            "replace /content/DryFruits-classification.v1i.coco/README.dataset.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!unzip /content/dry_fruit_detection_segmentation/datasets/labeled_dataset2/DryFruits-classification.v1i.coco.zip -d /content/DryFruits-classification.v1i.coco"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Wj1Zfy7OlQ37",
        "outputId": "319c13b6-b0e2-4151-8fbf-f370d9982478"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/dry_fruit_detection_segmentation/datasets/labeled_dataset2/DryFruits-Detection.v2i.coco.zip\n",
            "replace /content/DryFruits-Detection.v2i.coco/README.dataset.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!unzip /content/dry_fruit_detection_segmentation/datasets/labeled_dataset2/DryFruits-Detection.v2i.coco.zip -d /content/DryFruits-Detection.v2i.coco"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2fKXs0biVd3"
      },
      "outputs": [],
      "source": [
        "dataset_path = \"/content/DryFruits-Detection.v2i.coco\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hX5uA5z5iZue"
      },
      "outputs": [],
      "source": [
        "dataset = coco_dataset_dir(dataset_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RAIhUQZib9p",
        "outputId": "ae3f2e27-e2da-43b9-a776-d6a0c6b1a98a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ],
      "source": [
        "train_dataset, val_dataset, test_dataset = dataset.create_custom_datasets(ToTensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQpB7nlCidcs"
      },
      "outputs": [],
      "source": [
        "train_data_loader, val_data_loader, test_data_loader = CustomDataLoader(train_dataset, val_dataset, test_dataset, batch_size).create_data_loader()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NC6H7E2Rii8E"
      },
      "outputs": [],
      "source": [
        "from dry_fruit_detection_segmentation.utils import get_detection_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoD8Lwu0ivTG",
        "outputId": "47ea2540-344d-4e36-ddc9-f188ebb1a387"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "# extra class; for background\n",
        "num_classes = len(train_dataset.coco.getCatIds()) + 1\n",
        "model = get_detection_model(num_classes, custom_focal_loss=True)\n",
        "\n",
        "# move model to the right device\n",
        "model.to(device)\n",
        "\n",
        "# parameters\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "\n",
        "num_epochs = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zvpfq4R1ixDE"
      },
      "outputs": [],
      "source": [
        "best_map = 0.0\n",
        "epochs_no_improve = 0\n",
        "patience = 5  # stop if no improvement for 5 consecutive epochs\n",
        "model_name = \"detection_v2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6EIx51bi1A9",
        "outputId": "4301dff2-0acf-49bc-95e2-caf8f86b7db0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 1: 100%|██████████| 53/53 [00:40<00:00,  1.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 1] Training Loss: 0.2949\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:01<00:00,  2.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.02s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.450\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.712\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.460\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.450\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.579\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.643\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.643\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.643\n",
            "New best mAP: 0.4497 (previous best: 0.0000) — saving model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 2: 100%|██████████| 53/53 [00:40<00:00,  1.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 2] Training Loss: 0.1448\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:01<00:00,  2.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_False.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.496\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.851\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.451\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.496\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.593\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.593\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.593\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.593\n",
            "New best mAP: 0.4957 (previous best: 0.4497) — saving model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 3: 100%|██████████| 53/53 [00:40<00:00,  1.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 3] Training Loss: 0.1098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:01<00:00,  2.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_False.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.674\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.904\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.859\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.674\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.720\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.720\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.720\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.720\n",
            "New best mAP: 0.6744 (previous best: 0.4957) — saving model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 4: 100%|██████████| 53/53 [00:40<00:00,  1.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 4] Training Loss: 0.0884\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:01<00:00,  2.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_False.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.649\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.864\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.864\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.649\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.733\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.733\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.733\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.733\n",
            "No improvement in mAP for 1 epoch(s).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 5: 100%|██████████| 53/53 [00:40<00:00,  1.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 5] Training Loss: 0.0703\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:01<00:00,  2.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_False.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.646\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.892\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.892\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.646\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.700\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.700\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.700\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.700\n",
            "No improvement in mAP for 2 epoch(s).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 6: 100%|██████████| 53/53 [00:40<00:00,  1.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 6] Training Loss: 0.0651\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:01<00:00,  2.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_False.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.637\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.902\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.813\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.637\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.699\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.699\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.699\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.699\n",
            "No improvement in mAP for 3 epoch(s).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 7: 100%|██████████| 53/53 [00:40<00:00,  1.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 7] Training Loss: 0.0584\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:01<00:00,  2.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_False.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.666\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.928\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.866\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.666\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.703\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.703\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.703\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.703\n",
            "No improvement in mAP for 4 epoch(s).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 8: 100%|██████████| 53/53 [00:40<00:00,  1.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 8] Training Loss: 0.0558\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:01<00:00,  2.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_False.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.709\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.917\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.911\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.709\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.727\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.752\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.752\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.752\n",
            "New best mAP: 0.7091 (previous best: 0.6744) — saving model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 9: 100%|██████████| 53/53 [00:40<00:00,  1.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 9] Training Loss: 0.0484\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:01<00:00,  2.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_False.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.649\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.917\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.757\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.649\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.694\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.694\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.694\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.694\n",
            "No improvement in mAP for 1 epoch(s).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 10: 100%|██████████| 53/53 [00:40<00:00,  1.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 10] Training Loss: 0.0461\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:01<00:00,  2.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_False.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.753\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.928\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.928\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.753\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.782\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.782\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.782\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.782\n",
            "New best mAP: 0.7526 (previous best: 0.7091) — saving model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 11: 100%|██████████| 53/53 [00:40<00:00,  1.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 11] Training Loss: 0.0407\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:01<00:00,  2.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_False.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.683\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.911\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.911\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.683\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.739\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.739\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.739\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.739\n",
            "No improvement in mAP for 1 epoch(s).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 12: 100%|██████████| 53/53 [00:40<00:00,  1.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 12] Training Loss: 0.0429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:01<00:00,  2.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_False.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.716\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.886\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.886\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.716\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.773\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.773\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.773\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.773\n",
            "No improvement in mAP for 2 epoch(s).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 13: 100%|██████████| 53/53 [00:40<00:00,  1.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 13] Training Loss: 0.0357\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:01<00:00,  2.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_False.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.693\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.917\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.860\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.693\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.732\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.732\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.732\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.732\n",
            "No improvement in mAP for 3 epoch(s).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 14: 100%|██████████| 53/53 [00:40<00:00,  1.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 14] Training Loss: 0.0335\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:01<00:00,  2.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_False.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.733\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.922\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.922\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.733\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.772\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.772\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.772\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.772\n",
            "No improvement in mAP for 4 epoch(s).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 15: 100%|██████████| 53/53 [00:40<00:00,  1.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 15] Training Loss: 0.0315\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:01<00:00,  2.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_False.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.737\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.909\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.835\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.737\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.783\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.783\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.783\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.783\n",
            "No improvement in mAP for 5 epoch(s).\n",
            "Early stopping triggered after 15 epochs. Best mAP: 0.7526\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train_pipe(num_epochs, train_data_loader, model, val_data_loader, convert_to_coco_format, dataset\n",
        ", device, optimizer, model_name, patience=5, best_map=0.0, segmentation=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDtlZpXci4z-",
        "outputId": "56744c11-25ca-42fb-e973-080bbc37c52d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Video saved to test_video.mp4\n"
          ]
        }
      ],
      "source": [
        "create_video_from_images(dataset.test_dir, \"test_video.mp4\", fps=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "f4T4ANMIjBY4",
        "outputId": "82200955-6ead-46b0-b1de-a677589c4aef"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "FasterRCNN(\n",
              "  (transform): GeneralizedRCNNTransform(\n",
              "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
              "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
              "  )\n",
              "  (backbone): BackboneWithFPN(\n",
              "    (body): IntermediateLayerGetter(\n",
              "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (layer1): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer2): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer3): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (4): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (5): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer4): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (fpn): FeaturePyramidNetwork(\n",
              "      (inner_blocks): ModuleList(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (2): Conv2dNormActivation(\n",
              "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (layer_blocks): ModuleList(\n",
              "        (0-3): 4 x Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (extra_blocks): LastLevelMaxPool()\n",
              "    )\n",
              "  )\n",
              "  (rpn): RegionProposalNetwork(\n",
              "    (anchor_generator): AnchorGenerator()\n",
              "    (head): RPNHead(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (roi_heads): RoIHeads(\n",
              "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
              "    (box_head): TwoMLPHead(\n",
              "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
              "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    )\n",
              "    (box_predictor): FastRCNNPredictor(\n",
              "      (cls_score): Linear(in_features=1024, out_features=6, bias=True)\n",
              "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_save_path = f\"best_{model_name}_model.pth\"\n",
        "save_path = os.path.join(\"saved_models\", model_save_path)\n",
        "model = get_detection_model(num_classes, custom_focal_loss=True)\n",
        "model.load_state_dict(torch.load(save_path))\n",
        "model.to(device)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJ3JG-XRjEgK"
      },
      "outputs": [],
      "source": [
        "id_to_name = {\n",
        "    1: \"almond\",\n",
        "    2: \"cashew\",\n",
        "    3: \"grapes\",\n",
        "    4: \"raisin\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9DPzRnN2jIxf"
      },
      "outputs": [],
      "source": [
        "from dry_fruit_detection_segmentation.utils import save_predicted_video, save_predicted_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ez1-WhokmV4",
        "outputId": "1a4fb670-1d5f-4adf-bda3-229c259e01f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[✓] Inference time: 0.1218 seconds\n"
          ]
        }
      ],
      "source": [
        "save_predicted_image(dataset.test_dir+\"/360_F_1248363446_QWsdjuZlE2uK4sg1gCZSMogHM5d5SDqv_webp.rf.98746b3d6b7cd7d53599adf17435b3ff.jpg\", \"detection_out1.jpg\", model, device, id_to_name, threshold=0.4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVsU3WwyjVhM",
        "outputId": "b73596c1-db9e-4a88-d589-e010cf1b22de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[✓] Saved 10 annotated frames to video: detection_V2_out.mp4\n"
          ]
        }
      ],
      "source": [
        "save_predicted_video(\"test_video.mp4\", \"detection_V2_out.mp4\", model, device, id_to_name, threshold=0.4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dE662cxIjsvL",
        "outputId": "80b69a5a-71f6-41c8-c652-6168529178f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (5.29.5)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (4.13.2)\n",
            "Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m97.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx\n",
            "Successfully installed onnx-1.18.0\n"
          ]
        }
      ],
      "source": [
        "!pip install onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfcI9hm4jxEP"
      },
      "outputs": [],
      "source": [
        "from dry_fruit_detection_segmentation.utils import FasterRCNNWrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ydexL46rj8DT",
        "outputId": "6e622c13-a203-4048-a5f9-0ed1cc1ee039"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:4624: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  * torch.tensor(scale_factors[i], dtype=torch.float32)\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/ops/boxes.py:166: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  boxes_x = torch.min(boxes_x, torch.tensor(width, dtype=boxes.dtype, device=boxes.device))\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/ops/boxes.py:168: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  boxes_y = torch.min(boxes_y, torch.tensor(height, dtype=boxes.dtype, device=boxes.device))\n",
            "/usr/local/lib/python3.11/dist-packages/torch/__init__.py:2132: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert condition, message\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/detection/transform.py:308: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  torch.tensor(s, dtype=torch.float32, device=boxes.device)\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/detection/transform.py:309: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  / torch.tensor(s_orig, dtype=torch.float32, device=boxes.device)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/onnx/symbolic_opset9.py:5383: UserWarning: Exporting aten::index operator of advanced indexing in opset 11 is achieved by combination of multiple ONNX operators, including Reshape, Transpose, Concat, and Gather. If indices include negative values, the exported graph will produce incorrect results.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "wrapped_model = FasterRCNNWrapper(model)\n",
        "wrapped_model.cpu()\n",
        "wrapped_model.eval()\n",
        "\n",
        "dummy_input = torch.randn(1, 3, 640, 640)  # still on CPU\n",
        "\n",
        "# export\n",
        "torch.onnx.export(\n",
        "    wrapped_model,\n",
        "    dummy_input,\n",
        "    \"detection_v1.onnx\",\n",
        "    export_params=True,\n",
        "    opset_version=11,\n",
        "    input_names=[\"input\"],\n",
        "    output_names=[\"boxes\", \"labels\", \"scores\"],\n",
        "    dynamic_axes={\n",
        "        \"input\": {0: \"batch_size\"},\n",
        "        \"boxes\": {0: \"batch_size\"},\n",
        "        \"labels\": {0: \"batch_size\"},\n",
        "        \"scores\": {0: \"batch_size\"},\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUdy82SGj-sU"
      },
      "source": [
        "## MobileNet model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwvsLDgxj93e",
        "outputId": "7312ecc9-c02e-4dc2-8683-e070c00893c2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_MobileNet_V3_Large_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_MobileNet_V3_Large_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/fasterrcnn_mobilenet_v3_large_fpn-fb6a3cc7.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_mobilenet_v3_large_fpn-fb6a3cc7.pth\n",
            "100%|██████████| 74.2M/74.2M [00:00<00:00, 78.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "model = get_detection_model(num_classes, mobilenet=True, custom_focal_loss=True)\n",
        "model.to(device)\n",
        "\n",
        "# parameters\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "\n",
        "num_epochs = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmBfF9yikTse"
      },
      "outputs": [],
      "source": [
        "best_map = 0.0\n",
        "epochs_no_improve = 0\n",
        "patience = 5  # stop if no improvement for 5 consecutive epochs\n",
        "model_name = \"mobilenet_v2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gNuxEbhkb9K",
        "outputId": "0331e01a-6828-4fc9-d724-351ef24cf40e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 1: 100%|██████████| 53/53 [00:07<00:00,  6.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 1] Training Loss: 1.6053\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:00<00:00, 12.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_False.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.370\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.661\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.346\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.370\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.595\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.605\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.605\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.605\n",
            "New best mAP: 0.3700 (previous best: 0.0000) — saving model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 2: 100%|██████████| 53/53 [00:07<00:00,  7.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 2] Training Loss: 1.0607\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:00<00:00, 12.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_False.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.411\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.654\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.499\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.411\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.626\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.626\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.626\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.626\n",
            "New best mAP: 0.4110 (previous best: 0.3700) — saving model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 3: 100%|██████████| 53/53 [00:07<00:00,  7.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 3] Training Loss: 0.9366\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:00<00:00, 12.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_False.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.531\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.752\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.752\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.531\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.712\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.712\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.712\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.712\n",
            "New best mAP: 0.5312 (previous best: 0.4110) — saving model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 4: 100%|██████████| 53/53 [00:07<00:00,  6.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 4] Training Loss: 0.8331\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:00<00:00, 12.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_False.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.499\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.732\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.639\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.499\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.677\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.677\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.677\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.677\n",
            "No improvement in mAP for 1 epoch(s).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 5: 100%|██████████| 53/53 [00:07<00:00,  7.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 5] Training Loss: 0.6121\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:00<00:00, 12.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_False.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.535\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.654\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.654\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.535\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.700\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.700\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.700\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.700\n",
            "New best mAP: 0.5351 (previous best: 0.5312) — saving model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 6: 100%|██████████| 53/53 [00:07<00:00,  7.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 6] Training Loss: 0.6597\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:00<00:00, 12.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_False.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.621\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.799\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.799\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.621\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.743\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.743\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.743\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.743\n",
            "New best mAP: 0.6211 (previous best: 0.5351) — saving model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 7: 100%|██████████| 53/53 [00:07<00:00,  6.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 7] Training Loss: 0.6233\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:00<00:00, 12.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_False.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.544\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.750\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.701\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.544\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.693\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.693\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.693\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.693\n",
            "No improvement in mAP for 1 epoch(s).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 8: 100%|██████████| 53/53 [00:07<00:00,  7.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 8] Training Loss: 0.5611\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:00<00:00, 11.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_False.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.02s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.559\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.713\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.713\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.559\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.700\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.700\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.700\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.700\n",
            "No improvement in mAP for 2 epoch(s).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 9: 100%|██████████| 53/53 [00:07<00:00,  7.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 9] Training Loss: 0.5105\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:00<00:00, 12.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_False.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.649\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.818\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.818\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.649\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.781\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.781\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.781\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.781\n",
            "New best mAP: 0.6492 (previous best: 0.6211) — saving model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 10: 100%|██████████| 53/53 [00:07<00:00,  7.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 10] Training Loss: 0.4920\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:00<00:00, 10.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_False.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.669\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.837\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.837\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.669\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.775\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.775\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.775\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.775\n",
            "New best mAP: 0.6688 (previous best: 0.6492) — saving model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 11: 100%|██████████| 53/53 [00:06<00:00,  7.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 11] Training Loss: 0.4938\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:00<00:00, 12.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_False.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.600\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.789\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.715\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.600\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.754\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.754\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.754\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.754\n",
            "No improvement in mAP for 1 epoch(s).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 12: 100%|██████████| 53/53 [00:07<00:00,  7.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 12] Training Loss: 0.4639\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:00<00:00, 11.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_False.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.601\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.774\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.774\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.601\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.743\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.743\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.743\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.743\n",
            "No improvement in mAP for 2 epoch(s).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 13: 100%|██████████| 53/53 [00:07<00:00,  7.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 13] Training Loss: 0.4330\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:00<00:00, 11.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_False.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.574\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.762\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.762\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.574\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.690\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.690\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.690\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.690\n",
            "No improvement in mAP for 3 epoch(s).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 14: 100%|██████████| 53/53 [00:07<00:00,  7.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 14] Training Loss: 0.4491\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:00<00:00, 12.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_False.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.637\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.755\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.755\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.637\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.765\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.765\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.765\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.765\n",
            "No improvement in mAP for 4 epoch(s).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 15: 100%|██████████| 53/53 [00:07<00:00,  7.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 15] Training Loss: 0.3830\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:00<00:00, 12.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_False.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.698\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.888\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.888\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.698\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.768\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.768\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.768\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.768\n",
            "New best mAP: 0.6976 (previous best: 0.6688) — saving model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 16: 100%|██████████| 53/53 [00:07<00:00,  7.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 16] Training Loss: 0.3630\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:00<00:00, 12.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_False.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.691\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.847\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.847\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.691\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.787\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.787\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.787\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.787\n",
            "No improvement in mAP for 1 epoch(s).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 17: 100%|██████████| 53/53 [00:07<00:00,  7.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 17] Training Loss: 0.4391\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:00<00:00, 12.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_False.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.542\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.777\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.728\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.542\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.630\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.630\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.630\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.630\n",
            "No improvement in mAP for 2 epoch(s).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 18: 100%|██████████| 53/53 [00:07<00:00,  7.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 18] Training Loss: 0.4010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:00<00:00, 11.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_False.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.742\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.881\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.881\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.742\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.806\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.806\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.806\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.806\n",
            "New best mAP: 0.7418 (previous best: 0.6976) — saving model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 19: 100%|██████████| 53/53 [00:07<00:00,  7.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 19] Training Loss: 0.3894\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:00<00:00, 12.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_False.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.677\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.831\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.831\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.677\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.783\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.783\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.783\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.783\n",
            "No improvement in mAP for 1 epoch(s).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 20: 100%|██████████| 53/53 [00:07<00:00,  7.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 20] Training Loss: 0.4061\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:00<00:00, 12.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_False.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.706\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.851\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.851\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.706\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.798\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.798\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.798\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.798\n",
            "No improvement in mAP for 2 epoch(s).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 21: 100%|██████████| 53/53 [00:07<00:00,  7.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 21] Training Loss: 0.3547\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:00<00:00, 10.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_False.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.716\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.847\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.847\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.716\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.823\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.823\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.823\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.823\n",
            "No improvement in mAP for 3 epoch(s).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 22: 100%|██████████| 53/53 [00:07<00:00,  7.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 22] Training Loss: 0.3587\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:00<00:00, 12.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_False.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.668\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.805\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.805\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.668\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.760\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.760\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.760\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.760\n",
            "No improvement in mAP for 4 epoch(s).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 23: 100%|██████████| 53/53 [00:07<00:00,  7.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 23] Training Loss: 0.3591\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:00<00:00, 12.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_False.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.657\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.818\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.794\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.657\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.761\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.761\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.761\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.761\n",
            "No improvement in mAP for 5 epoch(s).\n",
            "Early stopping triggered after 23 epochs. Best mAP: 0.7418\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train_pipe(num_epochs, train_data_loader, model, val_data_loader, convert_to_coco_format, dataset\n",
        ", device, optimizer, model_name, patience=5, best_map=0.0, segmentation=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFlS6wgkkfdU",
        "outputId": "75feb245-8093-48c6-ddf3-727bfd043ca6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_MobileNet_V3_Large_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_MobileNet_V3_Large_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "FasterRCNN(\n",
              "  (transform): GeneralizedRCNNTransform(\n",
              "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
              "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
              "  )\n",
              "  (backbone): BackboneWithFPN(\n",
              "    (body): IntermediateLayerGetter(\n",
              "      (0): Conv2dNormActivation(\n",
              "        (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (1): FrozenBatchNorm2d(16, eps=1e-05)\n",
              "        (2): Hardswish()\n",
              "      )\n",
              "      (1): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
              "            (1): FrozenBatchNorm2d(16, eps=1e-05)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(16, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(64, eps=1e-05)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
              "            (1): FrozenBatchNorm2d(64, eps=1e-05)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): Conv2dNormActivation(\n",
              "            (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(24, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(72, eps=1e-05)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
              "            (1): FrozenBatchNorm2d(72, eps=1e-05)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): Conv2dNormActivation(\n",
              "            (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(24, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (4): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(72, eps=1e-05)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
              "            (1): FrozenBatchNorm2d(72, eps=1e-05)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Hardsigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(40, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (5): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(120, eps=1e-05)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
              "            (1): FrozenBatchNorm2d(120, eps=1e-05)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Hardsigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(40, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (6): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(120, eps=1e-05)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
              "            (1): FrozenBatchNorm2d(120, eps=1e-05)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Hardsigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(40, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (7): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(240, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
              "            (1): FrozenBatchNorm2d(240, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (2): Conv2dNormActivation(\n",
              "            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(80, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (8): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(200, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
              "            (1): FrozenBatchNorm2d(200, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (2): Conv2dNormActivation(\n",
              "            (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(80, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (9): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(184, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
              "            (1): FrozenBatchNorm2d(184, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (2): Conv2dNormActivation(\n",
              "            (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(80, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (10): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(184, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
              "            (1): FrozenBatchNorm2d(184, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (2): Conv2dNormActivation(\n",
              "            (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(80, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (11): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(480, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "            (1): FrozenBatchNorm2d(480, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Hardsigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(112, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (12): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(672, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
              "            (1): FrozenBatchNorm2d(672, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Hardsigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(112, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (13): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(672, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
              "            (1): FrozenBatchNorm2d(672, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Hardsigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(160, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (14): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(960, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
              "            (1): FrozenBatchNorm2d(960, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Hardsigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(160, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (15): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(960, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
              "            (1): FrozenBatchNorm2d(960, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Hardsigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(160, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (16): Conv2dNormActivation(\n",
              "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): FrozenBatchNorm2d(960, eps=1e-05)\n",
              "        (2): Hardswish()\n",
              "      )\n",
              "    )\n",
              "    (fpn): FeaturePyramidNetwork(\n",
              "      (inner_blocks): ModuleList(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(160, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(960, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (layer_blocks): ModuleList(\n",
              "        (0-1): 2 x Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (extra_blocks): LastLevelMaxPool()\n",
              "    )\n",
              "  )\n",
              "  (rpn): RegionProposalNetwork(\n",
              "    (anchor_generator): AnchorGenerator()\n",
              "    (head): RPNHead(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (cls_logits): Conv2d(256, 15, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bbox_pred): Conv2d(256, 60, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (roi_heads): RoIHeads(\n",
              "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
              "    (box_head): TwoMLPHead(\n",
              "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
              "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    )\n",
              "    (box_predictor): FastRCNNPredictor(\n",
              "      (cls_score): Linear(in_features=1024, out_features=6, bias=True)\n",
              "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_save_path = f\"best_{model_name}_model.pth\"\n",
        "save_path = os.path.join(\"saved_models\", model_save_path)\n",
        "model = get_detection_model(num_classes, mobilenet=True, custom_focal_loss=True)\n",
        "model.load_state_dict(torch.load(save_path))\n",
        "model.to(device)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IONH1CHIlkhG",
        "outputId": "507fbe33-69a1-425f-f1dd-0d57d222c5b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[✓] Inference time: 0.0250 seconds\n"
          ]
        }
      ],
      "source": [
        "save_predicted_image(dataset.test_dir+\"/360_F_1248363446_QWsdjuZlE2uK4sg1gCZSMogHM5d5SDqv_webp.rf.98746b3d6b7cd7d53599adf17435b3ff.jpg\", \"mobilenetv2_out1.jpg\", model, device, id_to_name, threshold=0.4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J06y297UkiNI"
      },
      "outputs": [],
      "source": [
        "save_predicted_video(\"test_video.mp4\", \"mobilenet_V2_out.mp4\", model, device, id_to_name, torch.threshold=0.4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SqHWLUFiEBc"
      },
      "source": [
        "#Segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hvp8icc1btqv",
        "outputId": "f9e2ed0e-7be9-42d2-8771-ab72e6822444"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/dry_fruit_detection_segmentation/datasets/labeled_dataset2/DryFruits-Segmentation.v2i.coco.zip\n",
            "  inflating: /content/DryFruits-Segmentation.v2i.coco/README.dataset.txt  \n",
            "  inflating: /content/DryFruits-Segmentation.v2i.coco/README.roboflow.txt  \n",
            "   creating: /content/DryFruits-Segmentation.v2i.coco/test/\n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/test/360_F_1248363446_QWsdjuZlE2uK4sg1gCZSMogHM5d5SDqv_webp.rf.ee5a89bca40b5620557c06690a160e4c.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/test/ALMOND_REGULAR_ALMOND_REGULAR_806_jpg.rf.de00fdc33a36d4aed2d2b3354c47ed7c.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/test/ALMOND_SANORA_ALMOND_SANORA_292_jpg.rf.089d18d7179d9d70c86f32037cafe374.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/test/ALMOND_SANORA_ALMOND_SANORA_905_jpg.rf.822d8eb52e60f587dfb543e358580f32.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/test/CASHEW_SPECIAL_CASHEW_SPECIAL_552_jpg.rf.62b04ab628eded93e865b6e49ca4c433.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/test/RAISIN_BLACK_RAISIN_BLACK_846_jpg.rf.8f7ce9cf72ed3f369ffa4f91d661f747.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/test/RAISIN_GRADE1_RAISIN_GRADE1_344_jpg.rf.5a6b1d3212ae6069ff2be0b23de88057.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/test/RAISIN_PREMIUM_RAISIN_PREMIUM_241_jpg.rf.78508ce0eae2320bb4ca5e71233fdc6a.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/test/RAISIN_PREMIUM_RAISIN_PREMIUM_811_jpg.rf.ebbd579cc734150e51b64bb7d2e4c220.jpg  \n",
            "  inflating: /content/DryFruits-Segmentation.v2i.coco/test/_annotations.coco.json  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/test/green-grapes-isolated-realistic-green-grapes-on-a-white-background-photo_webp.rf.687a6a1ee3d99ba765da8607d2df8da4.jpg  \n",
            "   creating: /content/DryFruits-Segmentation.v2i.coco/train/\n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/360_F_1085743617_TZyeDIVCjcw4XbqBolKU0WC5ZqNpJ9Rc_webp.rf.e1142f2a64bbea36505693474c21ab6a.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/360_F_1085743617_TZyeDIVCjcw4XbqBolKU0WC5ZqNpJ9Rc_webp.rf.fd289b4361e6674a4c5798e74e20ffd8.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/360_F_1085743617_TZyeDIVCjcw4XbqBolKU0WC5ZqNpJ9Rc_webp.rf.ffd0767c5e1404d614477f1f2c411308.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/360_F_1230381194_JkZ4wWbmrdZ0gWxZJXFR6aHQ391xSS2m_webp.rf.12ffe391cfd31e2fece1b1da8696131d.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/360_F_1230381194_JkZ4wWbmrdZ0gWxZJXFR6aHQ391xSS2m_webp.rf.1ac9575fec013cb7de087f6e4dc94331.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/360_F_1230381194_JkZ4wWbmrdZ0gWxZJXFR6aHQ391xSS2m_webp.rf.25254a4096a0334b9b552908f54704ed.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/360_F_1349652285_d44dCkFXh7AyjP71uTiMOGeyFWOlkqoZ_webp.rf.111c9b5d92c21fe59f425a1e9b50f09c.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/360_F_1349652285_d44dCkFXh7AyjP71uTiMOGeyFWOlkqoZ_webp.rf.a02d2e2a4a7290cf45a9fb86d0489119.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/360_F_1349652285_d44dCkFXh7AyjP71uTiMOGeyFWOlkqoZ_webp.rf.fad886b4f432f2da6e1373dc117e1e99.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/360_F_1398457747_LeARvSkUcjYXu0jUuKbWv436VgQ8TPK8_webp.rf.a67a479268eb0d8a8a91e8b091ffa4b3.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/360_F_1398457747_LeARvSkUcjYXu0jUuKbWv436VgQ8TPK8_webp.rf.af207e1c181952a42fc222c54a76dfe4.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/360_F_1398457747_LeARvSkUcjYXu0jUuKbWv436VgQ8TPK8_webp.rf.af27f0f1a5fba7753ba3c7e94a8cd86b.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_180_jpg.rf.37ee17e939f2b7fcd044663d619c8d87.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_180_jpg.rf.bb750825eccb079525d962449753ab74.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_180_jpg.rf.bb944c56d6f00bfd2034047e31645b57.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_192_jpg.rf.55fd5c86fbdf4e0be305920359529d6c.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_192_jpg.rf.8487cdfaf946c7b4149afe5dfcb93112.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_192_jpg.rf.abee63a84f4d23e30249d2c2966fe0a9.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_234_jpg.rf.46f823c8cf4db699821cf0294326eef2.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_234_jpg.rf.5baac51599565567f6fe1973c2b22baf.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_234_jpg.rf.7c3efaf6e808d2be9c08d85b101b62cb.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_599_jpg.rf.640bc4ad5abecf8ef3e03a231a31f1ff.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_599_jpg.rf.a96ec3754f74110a04926e0fb562b428.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_599_jpg.rf.c9d6d4afdd6f1d65047e20a2611deeae.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_740_jpg.rf.3d2c2e31cfdb828f8965df3aa1201a71.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_740_jpg.rf.5f49fcfdc1cf4dee1db211b9370db251.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_740_jpg.rf.822fb8c77dcf5504aff40c1af60691d8.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_778_jpg.rf.916b885d31c708fc5224240c30979874.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_778_jpg.rf.b9698b40a69bbb16f55fbf4dae738c72.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_MAMRA_ALMOND_MAMRA_778_jpg.rf.f6b7625cca6a66e4761fccd05f3f5628.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_285_jpg.rf.4e36e5db426615f7c9c8e115b37bd6dc.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_285_jpg.rf.5d8b962f4ff07b97ed160a769aaf09cd.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_285_jpg.rf.7079dd757319a1c29c21be84d32b679b.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_333_jpg.rf.11b593f44f7d6eac87f099a78a73edc8.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_333_jpg.rf.53bbb60e346647042e9f16b81252469c.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_333_jpg.rf.8ac7e0ed04d97e75005151ce1a797cbb.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_390_jpg.rf.4e3f066a9d456ab2fc869566f28a446b.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_390_jpg.rf.7152ed90dcc0d0d17b79de68ac43ddeb.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_390_jpg.rf.91781ce91ba1237454d18633d94f2f0b.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_402_jpg.rf.2246f08dca43bd06837a72e9a944389e.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_402_jpg.rf.379e0865a48d9d4d26c60f756d4c7230.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_402_jpg.rf.d14242aac4c48f29fc7a83a1a10f07c5.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_598_jpg.rf.64edc1df6093ada53c1101811daad038.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_598_jpg.rf.b3d0ec03b8665ced3a6460b52f96d011.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_598_jpg.rf.cac4bda21d8407f24e908f2db13bd39a.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_753_jpg.rf.7448acb77e0aff93d49c76f027e08691.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_753_jpg.rf.ba1109c7c35973cac89564831d9d5432.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_REGULAR_ALMOND_REGULAR_753_jpg.rf.eabb5711d782f916ab45c5c89a226d4c.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_SANORA_ALMOND_SANORA_113_jpg.rf.2372b61bb858713c69f927f67d94adbf.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_SANORA_ALMOND_SANORA_113_jpg.rf.3b4c7235cb0935a7484d6cbdbca252a4.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_SANORA_ALMOND_SANORA_113_jpg.rf.8f13603bad78977576cb70473ebc1d43.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_SANORA_ALMOND_SANORA_128_jpg.rf.58fd262db6e58b534f876591b54fd92d.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_SANORA_ALMOND_SANORA_128_jpg.rf.5ff789615f754679d6396ee1737e56e1.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_SANORA_ALMOND_SANORA_128_jpg.rf.d1c20b0c8e572f2511778fab49bcbb55.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_SANORA_ALMOND_SANORA_22_jpg.rf.2f105c1803611158e0c7b8736a0ae226.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_SANORA_ALMOND_SANORA_22_jpg.rf.a3fa49c3d2787b61d178b6ce0b0900ba.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_SANORA_ALMOND_SANORA_22_jpg.rf.a859e32db48c80c4b06d105c09ae1910.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_SANORA_ALMOND_SANORA_462_jpg.rf.2a48c67358c376fe2a6d71876042acd1.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_SANORA_ALMOND_SANORA_462_jpg.rf.e06e94453b8a3066e6bb63fcf6940723.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ALMOND_SANORA_ALMOND_SANORA_462_jpg.rf.f7c0dd28239e4868404ddee624fc799c.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_187_jpg.rf.07eb7a8796f7c86b4d61242ca6d8c480.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_187_jpg.rf.9c01ed0c3efcb2568bca788fad085bc1.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_187_jpg.rf.afb85fd6e5aab9b2985e317f29acd95e.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_310_jpg.rf.4b7b6769e194443390d76d1aa9a186e5.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_310_jpg.rf.abd0676232d9fa8372666674d6c9fa98.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_310_jpg.rf.e3b2ee00ae5163bf3ecc36d8b3719027.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_466_jpg.rf.13d11824af911c664dd12e911d036e7c.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_466_jpg.rf.6f1529492c73a2216c38eb9d2e4fcec4.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_466_jpg.rf.8f2567dec2cdd46d96061ae22c998628.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_471_jpg.rf.72907f6844929a3e55d0093333bbb5f5.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_471_jpg.rf.f8c3dd5676e062f75bee56b16c9fd51d.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_471_jpg.rf.ff43263db2b128d022e01087cc140e6a.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_479_jpg.rf.4257f625052c92fc7bcc5b7d285353b1.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_479_jpg.rf.83fa9aa5d6fd188bc182d853f6b4fdae.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_479_jpg.rf.f12300d084cef4f8d341b4b1415da8ab.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_510_jpg.rf.0a03601699139915bd90dc4553b33b8d.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_510_jpg.rf.342135631862dc96e5dff83f11f59bd1.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_510_jpg.rf.c3a25d6bf31e1c3ffae85a134c2d5e3c.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_797_jpg.rf.5e0aba4434362e611a82636c2a195f93.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_797_jpg.rf.a982a4f63991662a461782bec50c8f5a.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_797_jpg.rf.cd0d83209964720b8d070de66f9343b1.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_904_jpg.rf.923f51e7c466ff6535c0d622f08fca7f.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_904_jpg.rf.b16cc97bffe4d9d4ec9e8ebd12cc9d76.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_JUMBO_CASHEW_JUMBO_904_jpg.rf.bab7b9866281af2370c04bfc1d7ce408.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_200_jpg.rf.41d92a83f2d7c8eca85c1429dc9241cf.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_200_jpg.rf.6a26f36bea2e342ed790057a2869fb02.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_200_jpg.rf.b45da421d2c1fb8e7181ffff7aa4f343.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_394_jpg.rf.0bff77d0a82db8cbc8b69af9ec099bbc.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_394_jpg.rf.3798ef43dcb0d40a439c9c195fd5b845.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_394_jpg.rf.ba9d7c06828efbaf711c9fc185b3876a.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_605_jpg.rf.1bf8130d64a37609b31ed4676ed28669.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_605_jpg.rf.72ca4c915eafefe568d1efdbe231f715.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_605_jpg.rf.7c9b3498b0b653653de59a829c92c73d.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_737_jpg.rf.b856041ffd804ffe644099dfd25aea17.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_737_jpg.rf.e8779f6bd471a533d902443c7d503d0e.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_737_jpg.rf.f27af366a116265bab6c3b47d0d5aaa6.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_863_jpg.rf.64e3be5226d7bacacc866fb9b875053d.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_863_jpg.rf.9a4dbd470681b28c98e12512f2472ba0.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_863_jpg.rf.c8e63327715dfba9469b072fc29470b7.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_903_jpg.rf.4fb488ba6345a9d394b73d79f497b47a.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_903_jpg.rf.9434ff7bbed2d91ea5da4458654f46a5.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_REGULAR_CASHEW_REGULAR_903_jpg.rf.f7c22211f667056c3b2b0fa925610c85.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_171_jpg.rf.02c2e24ca301d851798a27d294863cfd.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_171_jpg.rf.2f985247b1bcb98b1b976aa2b5de42de.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_171_jpg.rf.5423ac28e9ee7a2baea2ec661ba18761.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_259_jpg.rf.192353e42aa86e8fed963fa0e58e853d.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_259_jpg.rf.c4590d47978bb062193dd2bcda4a17b1.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_259_jpg.rf.ca89a6ec39a5e83bbdb44c8daa8aa9d9.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_289_jpg.rf.659cbe49d654b6c152a92dd784fd87b8.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_289_jpg.rf.74f318dba9fe37ce4d35eb710dded6ad.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_289_jpg.rf.c9028e5b920c7da8bedf94a28d7a755c.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_46_jpg.rf.21fcc08f5b03a9c9d09e5152bbcbd7be.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_46_jpg.rf.a251827c15f4f9ffadbb9224764f9f6b.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_46_jpg.rf.d0fc4f4edcc5fa39299a1cfed9ad1d48.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_471_jpg.rf.0566861cd55ae76a33093c8865ca768d.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_471_jpg.rf.9cdc06611f986bd8b97de8773dec1f31.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_471_jpg.rf.c2228445712d8cecf7b5d86f7c5b3337.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_593_jpg.rf.7caab91b6310c7de25359c81daa42980.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_593_jpg.rf.a32012c0ddfabfaac5a65eeb9568abf1.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_593_jpg.rf.ec9a54b9b99381d5ddb4f3ad1459a510.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_724_jpg.rf.b5456f13b1701677d8231bb9c736e41a.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_724_jpg.rf.d36bc1bf86931eafa387b199d321adea.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/CASHEW_SPECIAL_CASHEW_SPECIAL_724_jpg.rf.da554b48e273cde3f921ef23b55585ae.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_128_jpg.rf.56ac59dfd413b1f8a683ef37e46b66c0.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_128_jpg.rf.c88e684a8419bff15b4eb7160cd4338d.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_128_jpg.rf.c9ef60fe38c2dc883c3ebc47d67f88c8.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_261_jpg.rf.5853118adbc7115a41d3f53fd3d91a79.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_261_jpg.rf.754d245bdd463a1226bff301febb5cd9.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_261_jpg.rf.f9354b88d78e22aed8adc6ffaf167ea1.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_568_jpg.rf.0e8bb682e7f29d685d493eb273afda02.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_568_jpg.rf.71d14e3dca15c9a21c747dde769f7205.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_568_jpg.rf.c3f1cd06b120f25a99ee249d8cbe794f.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_596_jpg.rf.3bbbedf1fc2f881264a7ca78232b5c2b.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_596_jpg.rf.6a4dddc29890904a846bf0e653d1ff0b.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_596_jpg.rf.7a25d010d1566ede7104e9cb605591ce.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_793_jpg.rf.1d420c190364b9d155e80cccb4543500.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_793_jpg.rf.201c21b9a87115350bc78aca0fb1fa28.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_793_jpg.rf.4ef1657e5e6f2d8deab1d804169348c1.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_812_jpg.rf.01027d62fb36d632149fb6cf320a2cc0.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_812_jpg.rf.3fdf8009d3aa6ff4597c0a6af05358c1.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_812_jpg.rf.df0b8e1d48ab068aa63fb957f60037c6.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_857_jpg.rf.ba7a9e973bbb8f39dea2e992e58d33c4.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_857_jpg.rf.d1b7bb8ee1ca362c1dc286265b57703d.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_BLACK_RAISIN_BLACK_857_jpg.rf.e38f797f32ffe5a735c07827b34d6875.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_GRADE1_RAISIN_GRADE1_251_jpg.rf.8d097a81db95a28e884396f966edabae.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_GRADE1_RAISIN_GRADE1_251_jpg.rf.99a0c5eb10d4ed2a329240307f3bccb7.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_GRADE1_RAISIN_GRADE1_251_jpg.rf.e9ce5071a5695d2d7f7591d2042cc251.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_GRADE1_RAISIN_GRADE1_293_jpg.rf.6a25973423bc3265e0e8757163be858c.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_GRADE1_RAISIN_GRADE1_293_jpg.rf.722c3715ee8ac5dd3342ceee33e9518b.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_GRADE1_RAISIN_GRADE1_293_jpg.rf.ae6677ec561f44fd28de7f9631fc1d28.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_GRADE1_RAISIN_GRADE1_726_jpg.rf.088511df8a8e1af99fb7cd616d0f3a5b.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_GRADE1_RAISIN_GRADE1_726_jpg.rf.17c1f4559229613b2e47e3de9583dcec.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_GRADE1_RAISIN_GRADE1_726_jpg.rf.fe8bc783a94f8cec0969e0d6c8ca910c.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_GRADE1_RAISIN_GRADE1_886_jpg.rf.2a97d9462f269b2737db870de6fca92a.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_GRADE1_RAISIN_GRADE1_886_jpg.rf.b4eb62751e4b686d4e435be583e5e53f.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_GRADE1_RAISIN_GRADE1_886_jpg.rf.e2258b514ee2fe4eecd40634ba9db789.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_186_jpg.rf.7ee140a9856360d442825fbac08b3c81.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_186_jpg.rf.843161b2e6193dccbe3a7a07085c86ab.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_186_jpg.rf.fbf52ec6aec68c4d893d9232b286e47e.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_244_jpg.rf.9d21239b73413e959786edbda5bc7d33.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_244_jpg.rf.c2e9ba10634ad14e4d1daffc6272e83a.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_244_jpg.rf.cff95e0fd48166ac8d2450f7c9bd5ded.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_256_jpg.rf.2931167a61f7f76a18fc5023b50bbc49.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_256_jpg.rf.4761b0732fc8eb1315a1ceca83493bd1.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_256_jpg.rf.5b003b5a5381f9b31216ef2cda6de507.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_25_jpg.rf.8e70c776dae5fc448c46390b3bcc5fc0.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_25_jpg.rf.c192f4f3bfa065353edd3bf7c76f9c1c.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_25_jpg.rf.d86474239d700460204d898a0dcd5fb1.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_73_jpg.rf.03fb4214a08280a0998085546e43c364.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_73_jpg.rf.468f1f8dee3c89cdeb83786bd60830b8.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/RAISIN_PREMIUM_RAISIN_PREMIUM_73_jpg.rf.50e8b7bf0cfa13dc88f82f6f04c37830.jpg  \n",
            "  inflating: /content/DryFruits-Segmentation.v2i.coco/train/_annotations.coco.json  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/a-single-grape-on-a-white-wall-photo_webp.rf.1637c610f72c92f88de988c44c64e893.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/a-single-grape-on-a-white-wall-photo_webp.rf.a7a942eeb0cb38cc16dd980ad6e33ded.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/a-single-grape-on-a-white-wall-photo_webp.rf.fed4e6c6291c2d1e838afedfe9e74acd.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/four-concord-grapes-isolated-on-white_webp.rf.3e50126e9b104f04a18d28d911dc480e.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/four-concord-grapes-isolated-on-white_webp.rf.bc9996a038f6cd0fb6155fce2d520dfd.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/four-concord-grapes-isolated-on-white_webp.rf.f21dccb94874eb1b0dca2d2639ae2112.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/front-view-of-fresh-red-grapes-with-half-in-stack-isolated-on-white-background-with-clipping-path-photo_webp.rf.3cbcc297588d495428430d3057276250.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/front-view-of-fresh-red-grapes-with-half-in-stack-isolated-on-white-background-with-clipping-path-photo_webp.rf.626a69badbc02c4899218d8d1734226f.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/front-view-of-fresh-red-grapes-with-half-in-stack-isolated-on-white-background-with-clipping-path-photo_webp.rf.d50352a9cf2bd68cf256f6efb7dc93b6.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/green-grape-isolated-on-white_webp.rf.54c5adfd59edf49eb6e91cd54f23f0ec.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/green-grape-isolated-on-white_webp.rf.599cfee23d4dd175c1b8febec2661efe.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/green-grape-isolated-on-white_webp.rf.e7943b4ca8133d12f2aac688f074297a.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/high-angle-view-grapes-white-fabric_1048944-17885048_webp.rf.1352ce36aa97622579ea6065fb0c00c5.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/high-angle-view-grapes-white-fabric_1048944-17885048_webp.rf.7fefe4af0f990b6fddacca31e202a9e4.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/high-angle-view-grapes-white-fabric_1048944-17885048_webp.rf.d18c8b2a8a41ddd8eefe6d0b2b9ca1d9.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/one-purple-grape-isolated-on-a-black-background-showing-the-details-of-the-skin-and-texture-free-photo_webp.rf.57d038eea28548a402b0e70f81d62629.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/one-purple-grape-isolated-on-a-black-background-showing-the-details-of-the-skin-and-texture-free-photo_webp.rf.d49dbd01734b5c8662f254e29e23da49.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/one-purple-grape-isolated-on-a-black-background-showing-the-details-of-the-skin-and-texture-free-photo_webp.rf.d5e700f0d4937a3fca990a885450970b.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/red-grape-macro_webp.rf.4ba427e382bb967dafe281cf8fa1dbbb.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/red-grape-macro_webp.rf.9521ffc4d9581c831753bb2d8f63f96d.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/red-grape-macro_webp.rf.a9849175e49eac8f958ae1d558710933.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/red-grape-on-white-background-close-up-free-photo_webp.rf.021a3d597bf2284211a726c4146559fd.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/red-grape-on-white-background-close-up-free-photo_webp.rf.594859fd77207bc016e53bcf621d713e.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/red-grape-on-white-background-close-up-free-photo_webp.rf.e676e0bb8d24e4ae36c6531fb62ceee2.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/red-seedless-grape_webp.rf.2fe076374a5322a95e7cde533dfd0370.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/red-seedless-grape_webp.rf.4a46b99346a3e4e47bc05f4ecc260f5f.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/red-seedless-grape_webp.rf.54e90328aba0d280260f204551990bd7.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ripe-red-grape-one-berry-260nw-503311102_webp.rf.3842743cb93e089eec09c2f813de4b4a.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ripe-red-grape-one-berry-260nw-503311102_webp.rf.81a122409e6bcd2e0cd87c3b35f511f4.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/ripe-red-grape-one-berry-260nw-503311102_webp.rf.f974995ca7bd03a94997ae4c5fece5b0.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/single-blue-grape-stem-isolated-260nw-152226398_webp.rf.36a074eb01549986b39727ba01ccfd84.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/single-blue-grape-stem-isolated-260nw-152226398_webp.rf.905074fa2de24330f6bdbcb0376b95e3.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/single-blue-grape-stem-isolated-260nw-152226398_webp.rf.a96f85785a88f5fc940149540f1f33d2.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/single-red-grape_webp.rf.5565292c9dd192163de63d574e844592.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/single-red-grape_webp.rf.6ec9a6baad564169f549ed5f2bc8f0af.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/single-red-grape_webp.rf.ebed73d295c6390c0e90c2934c9e0bb6.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/white-grapes_webp.rf.48ea747c09c057c4892483c720763ba5.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/white-grapes_webp.rf.b2fd4fc43fdaf18ca653cb047f243653.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/train/white-grapes_webp.rf.cd9eeb110c95b184451fef7dc486da3c.jpg  \n",
            "   creating: /content/DryFruits-Segmentation.v2i.coco/valid/\n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/valid/360_F_1218179377_guXOLpOhmvKU3CIiq9HuduiE1PWsofRu_webp.rf.20afe6835a63eaaf3c909d837d26cac0.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/valid/ALMOND_MAMRA_ALMOND_MAMRA_225_jpg.rf.3dcaa22b921ce8a1544a3fd11240b53c.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/valid/ALMOND_MAMRA_ALMOND_MAMRA_470_jpg.rf.6e77c73a1e5fc99c395490e34cc990e6.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/valid/ALMOND_MAMRA_ALMOND_MAMRA_7_jpg.rf.1156fad4657f61ea5443097fbae10e85.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/valid/ALMOND_REGULAR_ALMOND_REGULAR_578_jpg.rf.42471a772eaca2d304a3dc3d5bdc9da2.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/valid/ALMOND_SANORA_ALMOND_SANORA_429_jpg.rf.c40be853c3e3f3817db0be7a2f8109f8.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/valid/ALMOND_SANORA_ALMOND_SANORA_42_jpg.rf.8938726fc836a3f4a62226fc3b478642.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/valid/CASHEW_JUMBO_CASHEW_JUMBO_546_jpg.rf.c9bded083b5400cc729f4a4488633fed.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/valid/CASHEW_REGULAR_CASHEW_REGULAR_357_jpg.rf.0d84526d7e8363bf57803bc3ea4ad29f.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/valid/CASHEW_REGULAR_CASHEW_REGULAR_947_jpg.rf.0b001b5c3c102ebe0fa647ef4c30d0f5.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/valid/RAISIN_BLACK_RAISIN_BLACK_246_jpg.rf.7e8e786f6ff7b85d0b3de664c5309aeb.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/valid/RAISIN_GRADE1_RAISIN_GRADE1_258_jpg.rf.438b1b1360a04ccc905f0c9c8fb33e13.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/valid/RAISIN_GRADE1_RAISIN_GRADE1_421_jpg.rf.9d527a8ef3910fed3b6292e65ac4c08a.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/valid/RAISIN_GRADE1_RAISIN_GRADE1_77_jpg.rf.24ff7564b65216128730e3d4abc2ac6d.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/valid/RAISIN_PREMIUM_RAISIN_PREMIUM_164_jpg.rf.319366a9b055aa34a25aec7b3cb545d2.jpg  \n",
            "  inflating: /content/DryFruits-Segmentation.v2i.coco/valid/_annotations.coco.json  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/valid/black-grapes-isolated-on-white-background-photo_webp.rf.73051d3c82071a4e0ac0a38555e4bb83.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/valid/picture-with-a-fresh-red-grape_webp.rf.80a439b7c124835ffa767ff2ad454059.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/valid/ripe-red-grape-isolated-on-white-with-clipping-path-full-depth-of-field_webp.rf.1dc6409b9f990327718501bbe6e2bd62.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/valid/two-purple-grapes-with-green-stems_webp.rf.dec748accae0914de4ab7c0cba1abe7d.jpg  \n",
            " extracting: /content/DryFruits-Segmentation.v2i.coco/valid/wet-grape-on-white-background_webp.rf.ae3299c74d1755af68f89158458320e2.jpg  \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/dry_fruit_detection_segmentation/datasets/labeled_dataset2/DryFruits-Segmentation.v2i.coco.zip -d /content/DryFruits-Segmentation.v2i.coco"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlNOfxafVKz7"
      },
      "outputs": [],
      "source": [
        "dataset_path = \"/content/DryFruits-Segmentation.v2i.coco\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1z_RhTUVh-z"
      },
      "outputs": [],
      "source": [
        "dataset = coco_dataset_dir(dataset_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZzhH-2VdVkLK",
        "outputId": "1bad1e38-36d3-489c-a33e-035a7b8191c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ],
      "source": [
        "train_dataset, val_dataset, test_dataset = dataset.create_custom_datasets(ToTensor, segmentation=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2OqHTKboYA6n"
      },
      "outputs": [],
      "source": [
        "train_data_loader, val_data_loader, test_data_loader = CustomDataLoader(train_dataset, val_dataset, test_dataset, batch_size).create_data_loader()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBwaEGtMROoZ"
      },
      "outputs": [],
      "source": [
        "from dry_fruit_detection_segmentation.utils import get_segmentation_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfB3jR4ZdAUG",
        "outputId": "b63895e9-0053-425b-af72-e42c19220066"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MaskRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=MaskRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "# extra class; for background\n",
        "num_classes = len(train_dataset.coco.getCatIds()) + 1\n",
        "model = get_segmentation_model(num_classes, custom_focal_loss=True)\n",
        "\n",
        "# move model to the right device\n",
        "model.to(device)\n",
        "\n",
        "# parameters\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "\n",
        "num_epochs = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czS89_JUdGgH"
      },
      "outputs": [],
      "source": [
        "best_map = 0.0\n",
        "epochs_no_improve = 0\n",
        "patience = 5  # stop if no improvement for 5 consecutive epochs\n",
        "model_name = \"segmentation_v2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sUjvwUsykDoa",
        "outputId": "dfe16477-3106-4987-fc9a-8abaf5efb97c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining Epoch 1:   0%|          | 0/53 [00:00<?, ?it/s]/content/dry_fruit_detection_segmentation/src/data_setup.py:41: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
            "  masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
            "Training Epoch 1: 100%|██████████| 53/53 [00:57<00:00,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 1] Training Loss: 0.6049\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:03<00:00,  1.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.02s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.136\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.367\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.047\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.136\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.339\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.488\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.488\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.488\n",
            "New best mAP: 0.1356 (previous best: 0.0000) — saving model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 2: 100%|██████████| 53/53 [00:57<00:00,  1.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 2] Training Loss: 0.2548\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:03<00:00,  1.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_True.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.340\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.528\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.408\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.340\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.615\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.630\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.630\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.630\n",
            "New best mAP: 0.3404 (previous best: 0.1356) — saving model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 3: 100%|██████████| 53/53 [00:57<00:00,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 3] Training Loss: 0.1788\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:03<00:00,  1.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_True.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.501\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.609\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.609\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.501\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.792\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.792\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.792\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.792\n",
            "New best mAP: 0.5007 (previous best: 0.3404) — saving model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 4: 100%|██████████| 53/53 [00:57<00:00,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 4] Training Loss: 0.1452\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  1.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_True.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.513\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.686\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.686\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.513\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.718\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.718\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.718\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.718\n",
            "New best mAP: 0.5125 (previous best: 0.5007) — saving model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 5: 100%|██████████| 53/53 [00:57<00:00,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 5] Training Loss: 0.1218\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  1.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_True.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.02s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.641\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.772\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.695\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.641\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.797\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.797\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.797\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.797\n",
            "New best mAP: 0.6412 (previous best: 0.5125) — saving model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 6: 100%|██████████| 53/53 [00:57<00:00,  1.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 6] Training Loss: 0.1014\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  1.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_True.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.556\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.718\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.641\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.556\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.707\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.707\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.707\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.707\n",
            "No improvement in mAP for 1 epoch(s).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 7: 100%|██████████| 53/53 [00:57<00:00,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 7] Training Loss: 0.0993\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  1.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_True.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.567\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.746\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.670\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.570\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.747\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.747\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.747\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.747\n",
            "No improvement in mAP for 2 epoch(s).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 8: 100%|██████████| 53/53 [00:57<00:00,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 8] Training Loss: 0.0946\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  1.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_True.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.02s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.630\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.762\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.685\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.635\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.798\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.798\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.798\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.798\n",
            "No improvement in mAP for 3 epoch(s).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 9: 100%|██████████| 53/53 [00:57<00:00,  1.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 9] Training Loss: 0.0851\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  1.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_True.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.588\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.749\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.749\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.588\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.710\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.710\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.710\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.710\n",
            "No improvement in mAP for 4 epoch(s).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 10: 100%|██████████| 53/53 [00:56<00:00,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 10] Training Loss: 0.0814\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  1.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_True.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.667\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.785\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.708\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.667\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.812\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.812\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.812\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.812\n",
            "New best mAP: 0.6672 (previous best: 0.6412) — saving model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 11: 100%|██████████| 53/53 [00:57<00:00,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 11] Training Loss: 0.0766\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  1.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_True.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.02s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.708\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.831\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.762\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.708\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.812\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.812\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.812\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.812\n",
            "New best mAP: 0.7081 (previous best: 0.6672) — saving model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 12: 100%|██████████| 53/53 [00:57<00:00,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 12] Training Loss: 0.0761\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  1.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_True.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.692\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.843\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.766\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.692\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.798\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.798\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.798\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.798\n",
            "No improvement in mAP for 1 epoch(s).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 13: 100%|██████████| 53/53 [00:57<00:00,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 13] Training Loss: 0.0765\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  1.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_True.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.733\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.851\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.851\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.744\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.812\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.812\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.812\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.812\n",
            "New best mAP: 0.7329 (previous best: 0.7081) — saving model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 14: 100%|██████████| 53/53 [00:57<00:00,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 14] Training Loss: 0.0734\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  1.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_True.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.618\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.772\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.696\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.618\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.749\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.749\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.749\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.749\n",
            "No improvement in mAP for 1 epoch(s).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 15: 100%|██████████| 53/53 [00:57<00:00,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 15] Training Loss: 0.0695\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  1.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_True.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.679\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.799\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.722\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.688\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.816\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.816\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.816\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.816\n",
            "No improvement in mAP for 2 epoch(s).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 16: 100%|██████████| 53/53 [00:57<00:00,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 16] Training Loss: 0.0677\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  1.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_True.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.690\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.818\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.741\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.700\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.808\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.808\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.808\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.808\n",
            "No improvement in mAP for 3 epoch(s).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 17: 100%|██████████| 53/53 [00:57<00:00,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 17] Training Loss: 0.0683\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  1.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_True.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.715\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.814\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.737\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.727\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.833\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.833\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.833\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.833\n",
            "No improvement in mAP for 4 epoch(s).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 18: 100%|██████████| 53/53 [00:57<00:00,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 18] Training Loss: 0.0670\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 5/5 [00:03<00:00,  1.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing prediction file: coco_eval/predictions_True.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            "Validation Metrics:\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.676\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.790\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.713\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.709\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.818\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.818\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.818\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.818\n",
            "No improvement in mAP for 5 epoch(s).\n",
            "Early stopping triggered after 18 epochs. Best mAP: 0.7329\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train_pipe(num_epochs, train_data_loader, model, val_data_loader, convert_to_coco_format, dataset\n",
        ", device, optimizer, model_name, patience=5, best_map=0.0, segmentation=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "024UVZPjA31R"
      },
      "outputs": [],
      "source": [
        "create_video_from_images(dataset.test_dir, \"object_segmentation_in.mp4\", fps=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rfOWjL0ABLpN",
        "outputId": "bfeded03-307e-4775-e75d-044c2429d175"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MaskRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=MaskRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "MaskRCNN(\n",
              "  (transform): GeneralizedRCNNTransform(\n",
              "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
              "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
              "  )\n",
              "  (backbone): BackboneWithFPN(\n",
              "    (body): IntermediateLayerGetter(\n",
              "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (layer1): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer2): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer3): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (4): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (5): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer4): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (fpn): FeaturePyramidNetwork(\n",
              "      (inner_blocks): ModuleList(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (2): Conv2dNormActivation(\n",
              "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (layer_blocks): ModuleList(\n",
              "        (0-3): 4 x Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (extra_blocks): LastLevelMaxPool()\n",
              "    )\n",
              "  )\n",
              "  (rpn): RegionProposalNetwork(\n",
              "    (anchor_generator): AnchorGenerator()\n",
              "    (head): RPNHead(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (roi_heads): RoIHeads(\n",
              "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
              "    (box_head): TwoMLPHead(\n",
              "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
              "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    )\n",
              "    (box_predictor): FastRCNNPredictor(\n",
              "      (cls_score): Linear(in_features=1024, out_features=6, bias=True)\n",
              "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
              "    )\n",
              "    (mask_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(14, 14), sampling_ratio=2)\n",
              "    (mask_head): MaskRCNNHeads(\n",
              "      (0): Conv2dNormActivation(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (1): Conv2dNormActivation(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Conv2dNormActivation(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Conv2dNormActivation(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (mask_predictor): MaskRCNNPredictor(\n",
              "      (conv5_mask): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (mask_fcn_logits): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_save_path = f\"best_{model_name}_model.pth\"\n",
        "save_path = os.path.join(\"saved_models\", model_save_path)\n",
        "model = get_segmentation_model(num_classes, custom_focal_loss=False)\n",
        "model.load_state_dict(torch.load(save_path))\n",
        "model.to(device)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1Q_4eADCbTL"
      },
      "outputs": [],
      "source": [
        "example_img = \"/content/DryFruits-Segmentation.v2i.coco/test/360_F_1248363446_QWsdjuZlE2uK4sg1gCZSMogHM5d5SDqv_webp.rf.ee5a89bca40b5620557c06690a160e4c.jpg\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxuoDmTbyBda"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBXnqUiVYyI3"
      },
      "outputs": [],
      "source": [
        "basic_colors = {\n",
        "    'red': (255, 0, 0),\n",
        "    'green': (0, 128, 0),\n",
        "    'blue': (0, 0, 255),\n",
        "    'yellow': (255, 255, 0),\n",
        "    #'cyan': (0, 255, 255),\n",
        "    #'magenta': (255, 0, 255),\n",
        "    'black': (0, 0, 0),\n",
        "    #'white': (255, 255, 255),\n",
        "    'gray': (128, 128, 128),\n",
        "    'orange': (255, 165, 0),\n",
        "    #'brown': (165, 42, 42),\n",
        "    'purple': (128, 0, 128),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kc5keEC_hi1l"
      },
      "outputs": [],
      "source": [
        "from dry_fruit_detection_segmentation.utils import closest_basic_color_name, detect_shape, save_segmented_image, save_segmented_video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CeNrs4kkxlpV",
        "outputId": "8ec34d8b-0605-4635-bfd0-3aff3b741e53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[✓] Inference time: 0.1228 seconds\n",
            "[✓] Saved segmented image to: segment_v2_output.jpg\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/dry_fruit_detection_segmentation/utils.py:432: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  dist = sum((rc - cc) ** 2 for rc, cc in zip(requested_color, rgb))\n",
            "/content/dry_fruit_detection_segmentation/utils.py:432: RuntimeWarning: overflow encountered in scalar add\n",
            "  dist = sum((rc - cc) ** 2 for rc, cc in zip(requested_color, rgb))\n"
          ]
        }
      ],
      "source": [
        "save_segmented_image(example_img, \"segment_v2_output.jpg\", model, device, id_to_name, basic_colors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kaWkjB4rYVnQ",
        "outputId": "57951a38-ae47-4f24-b8ec-952c64de5811"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[✓] Inference time: 0.1267 seconds\n",
            "[✓] Saved segmented image to: object_segmentation_out.mp4/frame_00000.jpg\n",
            "[✓] Inference time: 0.1230 seconds\n",
            "[✓] Saved segmented image to: object_segmentation_out.mp4/frame_00001.jpg\n",
            "[✓] Inference time: 0.0816 seconds\n",
            "[✓] Saved segmented image to: object_segmentation_out.mp4/frame_00002.jpg\n",
            "[✓] Inference time: 0.0815 seconds\n",
            "[✓] Saved segmented image to: object_segmentation_out.mp4/frame_00003.jpg\n",
            "[✓] Inference time: 0.0803 seconds\n",
            "[✓] Saved segmented image to: object_segmentation_out.mp4/frame_00004.jpg\n",
            "[✓] Inference time: 0.0773 seconds\n",
            "[✓] Saved segmented image to: object_segmentation_out.mp4/frame_00005.jpg\n",
            "[✓] Inference time: 0.0826 seconds\n",
            "[✓] Saved segmented image to: object_segmentation_out.mp4/frame_00006.jpg\n",
            "[✓] Inference time: 0.0836 seconds\n",
            "[✓] Saved segmented image to: object_segmentation_out.mp4/frame_00007.jpg\n",
            "[✓] Inference time: 0.0830 seconds\n",
            "[✓] Saved segmented image to: object_segmentation_out.mp4/frame_00008.jpg\n",
            "[✓] Inference time: 0.0775 seconds\n",
            "[✓] Saved segmented image to: object_segmentation_out.mp4/frame_00009.jpg\n",
            "[✓] Saved 10 segmented frames to: object_segmentation_out.mp4\n"
          ]
        }
      ],
      "source": [
        "save_segmented_video(\"object_segmentation_in.mp4\", \"object_segmentation_out.mp4\", model, device, id_to_name, basic_colors, threshold=0.4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OKy5v1abSKt"
      },
      "outputs": [],
      "source": [
        "from dry_fruit_detection_segmentation.utils import MaskRCNNWrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZXMcW6tP3ruv",
        "outputId": "cdbf48a0-7273-4207-d506-564a36d59ce1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:4624: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  * torch.tensor(scale_factors[i], dtype=torch.float32)\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/ops/boxes.py:166: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  boxes_x = torch.min(boxes_x, torch.tensor(width, dtype=boxes.dtype, device=boxes.device))\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/ops/boxes.py:168: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  boxes_y = torch.min(boxes_y, torch.tensor(height, dtype=boxes.dtype, device=boxes.device))\n",
            "/usr/local/lib/python3.11/dist-packages/torch/__init__.py:2132: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert condition, message\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/detection/transform.py:308: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  torch.tensor(s, dtype=torch.float32, device=boxes.device)\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/detection/transform.py:309: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  / torch.tensor(s_orig, dtype=torch.float32, device=boxes.device)\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/detection/roi_heads.py:389: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return torch.tensor(M + 2 * padding).to(torch.float32) / torch.tensor(M).to(torch.float32)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/onnx/symbolic_opset9.py:5383: UserWarning: Exporting aten::index operator of advanced indexing in opset 11 is achieved by combination of multiple ONNX operators, including Reshape, Transpose, Concat, and Gather. If indices include negative values, the exported graph will produce incorrect results.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/onnx/_internal/jit_utils.py:308: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at /pytorch/torch/csrc/jit/passes/onnx/constant_fold.cpp:178.)\n",
            "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/onnx/utils.py:657: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at /pytorch/torch/csrc/jit/passes/onnx/constant_fold.cpp:178.)\n",
            "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/onnx/utils.py:1127: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at /pytorch/torch/csrc/jit/passes/onnx/constant_fold.cpp:178.)\n",
            "  _C._jit_pass_onnx_graph_shape_type_inference(\n"
          ]
        }
      ],
      "source": [
        "wrapped_model = MaskRCNNWrapper(model)\n",
        "wrapped_model.cpu()\n",
        "wrapped_model.eval()\n",
        "\n",
        "dummy_input = torch.randn(1, 3, 640, 640)  # still on CPU\n",
        "\n",
        "# export\n",
        "torch.onnx.export(\n",
        "    wrapped_model,\n",
        "    dummy_input,\n",
        "    \"segmentation_v1.onnx\",\n",
        "    export_params=True,\n",
        "    opset_version=11,\n",
        "    input_names=[\"input\"],\n",
        "    output_names=[\"boxes\", \"labels\", \"scores\", \"masks\"],\n",
        "    dynamic_axes={\n",
        "        \"input\": {0: \"batch_size\"},\n",
        "        \"boxes\": {0: \"batch_size\"},\n",
        "        \"labels\": {0: \"batch_size\"},\n",
        "        \"scores\": {0: \"batch_size\"},\n",
        "        \"masks\": {0: \"batch_size\"},\n",
        "    }\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
